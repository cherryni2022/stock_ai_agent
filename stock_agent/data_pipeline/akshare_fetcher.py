"""akshare data fetcher â€” Aè‚¡æ—¥Kçº¿ + åŸºæœ¬ä¿¡æ¯/å…¬å¸ä¿¡æ¯è·å–.

Covers tasks 1.2.1, 1.2.4 in the development plan.

Usage:
    # é»˜è®¤: MVP è‚¡ç¥¨æ± , 5 å¹´æ•°æ®
    python -m stock_agent.data_pipeline.akshare_fetcher

    # æŒ‡å®š ticker å’Œ period
    python -m stock_agent.data_pipeline.akshare_fetcher --tickers 601127 --period 1y
    python -m stock_agent.data_pipeline.akshare_fetcher --tickers 601127 688981 --period 3y
"""

import argparse
import asyncio
import logging
import re
from datetime import datetime, timedelta

import akshare as ak
import pandas as pd

from stock_agent.config import get_settings
from stock_agent.database.models.stock import (
    StockBasicInfoDB,
    StockCompanyInfoDB,
    StockDailyPriceDB,
)
from stock_agent.database.session import get_session

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(name)s: %(message)s")
logger = logging.getLogger(__name__)


# ---- Helper Functions ----


def _akshare_daily_to_entities(
    df: pd.DataFrame,
    ticker: str,
    stock_name: str = "",
) -> list[StockDailyPriceDB]:
    """Convert akshare stock_zh_a_hist DataFrame to ORM entities.

    akshare stock_zh_a_hist columns:
    æ—¥æœŸ, å¼€ç›˜, æ”¶ç›˜, æœ€é«˜, æœ€ä½, æˆäº¤é‡, æˆäº¤é¢, æŒ¯å¹…, æ¶¨è·Œå¹…, æ¶¨è·Œé¢, æ¢æ‰‹ç‡
    """
    entities = []
    for _, row in df.iterrows():
        trade_date = str(row.get("æ—¥æœŸ", ""))[:10]

        entity = StockDailyPriceDB(
            ticker=ticker,
            name=stock_name,
            trade_date=trade_date,
            open=_safe_float(row.get("å¼€ç›˜")),
            high=_safe_float(row.get("æœ€é«˜")),
            low=_safe_float(row.get("æœ€ä½")),
            close=_safe_float(row.get("æ”¶ç›˜")),
            volume=_safe_int(row.get("æˆäº¤é‡")),
            amount=_safe_float(row.get("æˆäº¤é¢")),
            amplitude=_safe_float(row.get("æŒ¯å¹…")),
            pct_change=_safe_float(row.get("æ¶¨è·Œå¹…")),
            amount_change=_safe_float(row.get("æ¶¨è·Œé¢")),
            turnover_rate=_safe_float(row.get("æ¢æ‰‹ç‡")),
        )
        entities.append(entity)
    return entities


def _safe_float(val) -> float | None:
    """Safe float conversion."""
    try:
        if pd.isna(val):
            return None
        return round(float(val), 4)
    except (TypeError, ValueError):
        return None


def _safe_int(val) -> int | None:
    """Safe int conversion."""
    try:
        if pd.isna(val):
            return None
        return int(val)
    except (TypeError, ValueError):
        return None


# ---- Period Helpers ----

_PERIOD_DAYS: dict[str, int] = {
    "1y": 365,
    "2y": 730,
    "3y": 1095,
    "5y": 1825,
    "10y": 3650,
}


def _period_to_dates(period: str) -> tuple[str, str]:
    """Convert period string like '5y' to (start_date, end_date) in 'YYYYMMDD' format."""
    end = datetime.now()
    end_str = end.strftime("%Y%m%d")

    if period in _PERIOD_DAYS:
        start = end - timedelta(days=_PERIOD_DAYS[period])
    elif re.match(r"^\d+y$", period):
        years = int(period[:-1])
        start = end - timedelta(days=years * 365)
    else:
        # Fallback: treat as 5y
        start = end - timedelta(days=1825)

    return start.strftime("%Y%m%d"), end_str


# ---- Main Fetch Functions ----


async def fetch_a_share_daily_prices(
    tickers: list[str] | None = None,
    period: str = "5y",
    start_date: str | None = None,
    end_date: str | None = None,
) -> None:
    """Task 1.2.1: è·å–Aè‚¡æ—¥Kçº¿.

    Args:
        tickers: Aè‚¡ ticker åˆ—è¡¨, ä¸ºç©ºæ—¶ä½¿ç”¨ MVP è‚¡ç¥¨æ± .
        period: æ•°æ®å‘¨æœŸ, å¦‚ '1y', '2y', '5y'. å½“ start_date/end_date æœªæŒ‡å®šæ—¶ç”Ÿæ•ˆ.
        start_date: èµ·å§‹æ—¥æœŸ, æ ¼å¼ 'YYYYMMDD'. ä¼˜å…ˆäº period.
        end_date: ç»“æŸæ—¥æœŸ, æ ¼å¼ 'YYYYMMDD'. ä¼˜å…ˆäº period.
    """
    if not tickers:
        settings = get_settings()
        tickers = settings.MVP_STOCK_UNIVERSE["CN"]

    if not start_date or not end_date:
        computed_start, computed_end = _period_to_dates(period)
        start_date = start_date or computed_start
        end_date = end_date or computed_end

    logger.info(f"ğŸ“Š å¼€å§‹è·å–Aè‚¡æ—¥Kçº¿: {tickers} ({start_date} ~ {end_date})")

    async with get_session() as session:
        total_rows = 0
        for ticker in tickers:
            try:
                logger.info(f"  â†’ è·å– {ticker} ...")
                # akshare: stock_zh_a_hist è·å–ä¸ªè‚¡æ—¥Kçº¿
                df = ak.stock_zh_a_hist(
                    symbol=ticker,
                    period="daily",
                    start_date=start_date,
                    end_date=end_date,
                    adjust="qfq",  # å‰å¤æƒ
                )

                if df.empty:
                    logger.warning(f"  âš  {ticker} æ— æ•°æ®")
                    continue

                # Try to get stock name
                stock_name = ""
                try:
                    spot_df = ak.stock_individual_info_em(symbol=ticker)
                    if not spot_df.empty:
                        name_row = spot_df[spot_df["item"] == "è‚¡ç¥¨ç®€ç§°"]
                        if not name_row.empty:
                            stock_name = str(name_row.iloc[0]["value"])
                except Exception:
                    pass

                entities = _akshare_daily_to_entities(df, ticker, stock_name)

                session.add_all(entities)
                await session.flush()
                total_rows += len(entities)
                logger.info(f"  âœ… {ticker} ({stock_name}): {len(entities)} è¡Œå†™å…¥")

            except Exception as e:
                logger.error(f"  âŒ {ticker} è·å–å¤±è´¥: {e}")
                continue

        logger.info(f"ğŸ“Š Aè‚¡æ—¥Kçº¿è·å–å®Œæˆ, å…± {total_rows} è¡Œ")


async def fetch_a_share_basic_info(tickers: list[str] | None = None) -> None:
    """Task 1.2.4 (part 1): è·å–Aè‚¡åŸºæœ¬ä¿¡æ¯ (akshare ä¸ªè‚¡ä¿¡æ¯).

    Args:
        tickers: Aè‚¡ ticker åˆ—è¡¨, ä¸ºç©ºæ—¶ä½¿ç”¨ MVP è‚¡ç¥¨æ± .
    """
    if not tickers:
        settings = get_settings()
        tickers = settings.MVP_STOCK_UNIVERSE["CN"]
    logger.info(f"ğŸ“‹ å¼€å§‹è·å–Aè‚¡åŸºæœ¬ä¿¡æ¯: {tickers}")

    async with get_session() as session:
        for ticker in tickers:
            try:
                logger.info(f"  â†’ è·å– {ticker} åŸºæœ¬ä¿¡æ¯ ...")
                # akshare: stock_individual_info_em è·å–ä¸ªè‚¡åŸºæœ¬ä¿¡æ¯
                df = ak.stock_individual_info_em(symbol=ticker)

                if df.empty:
                    logger.warning(f"  âš  {ticker} æ— åŸºæœ¬ä¿¡æ¯")
                    continue

                # Convert to dict for easier access
                info_dict = {}
                for _, row in df.iterrows():
                    info_dict[row["item"]] = row["value"]

                # Also get spot price data for market cap, etc.
                try:
                    spot_df = ak.stock_zh_a_spot_em()
                    spot_row = spot_df[spot_df["ä»£ç "] == ticker]
                    if not spot_row.empty:
                        spot = spot_row.iloc[0]
                    else:
                        spot = None
                except Exception:
                    spot = None

                entity = StockBasicInfoDB(
                    ticker=ticker,
                    stock_name=str(info_dict.get("è‚¡ç¥¨ç®€ç§°", "")),
                    total_shares=_safe_float(info_dict.get("æ€»è‚¡æœ¬", None)),
                    float_shares=_safe_float(info_dict.get("æµé€šè‚¡", None)),
                    total_market_value=_safe_float(spot.get("æ€»å¸‚å€¼")) if spot is not None else None,
                    float_market_value=_safe_float(spot.get("æµé€šå¸‚å€¼")) if spot is not None else None,
                    industry=str(info_dict.get("è¡Œä¸š", "")),
                    listing_date=str(info_dict.get("ä¸Šå¸‚æ—¶é—´", "")),
                    latest_price=_safe_float(spot.get("æœ€æ–°ä»·")) if spot is not None else None,
                )
                session.add(entity)
                await session.flush()
                logger.info(f"  âœ… {ticker}: {info_dict.get('è‚¡ç¥¨ç®€ç§°', 'N/A')}")

            except Exception as e:
                logger.error(f"  âŒ {ticker} åŸºæœ¬ä¿¡æ¯è·å–å¤±è´¥: {e}")
                continue

    logger.info("ğŸ“‹ Aè‚¡åŸºæœ¬ä¿¡æ¯è·å–å®Œæˆ")


async def fetch_a_share_company_info(tickers: list[str] | None = None) -> None:
    """Task 1.2.4 (part 2): è·å–Aè‚¡å…¬å¸ä¿¡æ¯ (è¯¦ç»†).

    Args:
        tickers: Aè‚¡ ticker åˆ—è¡¨, ä¸ºç©ºæ—¶ä½¿ç”¨ MVP è‚¡ç¥¨æ± .
    """
    if not tickers:
        settings = get_settings()
        tickers = settings.MVP_STOCK_UNIVERSE["CN"]
    logger.info(f"ğŸ“‹ å¼€å§‹è·å–Aè‚¡å…¬å¸è¯¦ç»†ä¿¡æ¯: {tickers}")

    async with get_session() as session:
        for ticker in tickers:
            try:
                logger.info(f"  â†’ è·å– {ticker} å…¬å¸ä¿¡æ¯ ...")
                df = ak.stock_individual_info_em(symbol=ticker)

                if df.empty:
                    logger.warning(f"  âš  {ticker} æ— å…¬å¸ä¿¡æ¯")
                    continue

                info_dict = {}
                for _, row in df.iterrows():
                    info_dict[row["item"]] = row["value"]

                entity = StockCompanyInfoDB(
                    ticker=ticker,
                    company_name=str(info_dict.get("è‚¡ç¥¨ç®€ç§°", "")),
                    english_name=str(info_dict.get("", "")),  # akshare may not have this
                    a_share_abbreviation=str(info_dict.get("è‚¡ç¥¨ç®€ç§°", "")),
                    market=str(info_dict.get("ä¸Šå¸‚å¸‚åœº", "")),
                    industry=str(info_dict.get("è¡Œä¸š", "")),
                    listing_date=str(info_dict.get("ä¸Šå¸‚æ—¶é—´", "")),
                )
                session.add(entity)
                await session.flush()
                logger.info(f"  âœ… {ticker}: {info_dict.get('è‚¡ç¥¨ç®€ç§°', 'N/A')}")

            except Exception as e:
                logger.error(f"  âŒ {ticker} å…¬å¸ä¿¡æ¯è·å–å¤±è´¥: {e}")
                continue

    logger.info("ğŸ“‹ Aè‚¡å…¬å¸ä¿¡æ¯è·å–å®Œæˆ")


async def fetch_all_akshare_data(
    tickers: list[str] | None = None,
    period: str = "5y",
) -> None:
    """è¿è¡Œæ‰€æœ‰ akshare æ•°æ®è·å–ä»»åŠ¡.

    Args:
        tickers: Aè‚¡ ticker åˆ—è¡¨. ä¸ºç©ºæ—¶ä½¿ç”¨ MVP è‚¡ç¥¨æ± .
        period: æ•°æ®å‘¨æœŸ, å¦‚ '1y', '2y', '5y'. é»˜è®¤ '5y'.
    """
    logger.info("=" * 60)
    logger.info("ğŸš€ å¼€å§‹ akshare æ•°æ®è·å–")
    logger.info("=" * 60)

    await fetch_a_share_daily_prices(tickers=tickers, period=period)
    await fetch_a_share_basic_info(tickers=tickers)
    await fetch_a_share_company_info(tickers=tickers)

    logger.info("=" * 60)
    logger.info("ğŸ‰ akshare æ•°æ®è·å–å®Œæˆ!")
    logger.info("=" * 60)


def _parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="akshare Aè‚¡æ•°æ®è·å–")
    parser.add_argument(
        "--tickers",
        nargs="+",
        default=None,
        help="æŒ‡å®š Aè‚¡ ticker åˆ—è¡¨, ä¾‹å¦‚ 601127 688981. ä¸ºç©ºæ—¶ä½¿ç”¨ MVP è‚¡ç¥¨æ± .",
    )
    parser.add_argument(
        "--period",
        default="5y",
        help="æ•°æ®å‘¨æœŸ, å¦‚ 1y/2y/5y (é»˜è®¤: 5y)",
    )
    return parser.parse_args()


if __name__ == "__main__":
    args = _parse_args()
    asyncio.run(fetch_all_akshare_data(tickers=args.tickers, period=args.period))
