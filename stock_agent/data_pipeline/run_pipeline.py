"""Unified data pipeline runner â€” orchestrates all data fetching tasks.

Usage:
    python -m stock_agent.data_pipeline.run_pipeline          # å…¨é‡
    python -m stock_agent.data_pipeline.run_pipeline --market CN   # ä»…Aè‚¡
    python -m stock_agent.data_pipeline.run_pipeline --market HK   # ä»…æ¸¯è‚¡
    python -m stock_agent.data_pipeline.run_pipeline --market US   # ä»…ç¾Žè‚¡
"""

import argparse
import asyncio
import logging
import time

from stock_agent.data_pipeline.akshare_fetcher import (
    fetch_a_share_basic_info,
    fetch_a_share_company_info,
    fetch_a_share_daily_prices,
)
from stock_agent.data_pipeline.financial_fetcher import fetch_all_financial_data
from stock_agent.data_pipeline.indicator_calculator import calculate_all_indicators
from stock_agent.data_pipeline.yfinance_fetcher import (
    fetch_hk_basic_info,
    fetch_hk_daily_prices,
    fetch_us_basic_info,
    fetch_us_daily_prices,
)

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(name)s: %(message)s")
logger = logging.getLogger(__name__)


async def run_pipeline(market: str | None = None) -> None:
    """Run data pipeline for specified market(s).

    Args:
        market: "CN", "HK", "US", or None for all.
    """
    start = time.perf_counter()
    logger.info("=" * 60)
    logger.info("ðŸš€ Stock Data Pipeline â€” Starting")
    logger.info(f"   Target market: {market or 'ALL'}")
    logger.info("=" * 60)

    tasks: list[tuple[str, object]] = []

    if market is None or market == "CN":
        tasks.extend([
            ("Aè‚¡æ—¥Kçº¿", fetch_a_share_daily_prices()),
            ("Aè‚¡åŸºæœ¬ä¿¡æ¯", fetch_a_share_basic_info()),
            ("Aè‚¡å…¬å¸ä¿¡æ¯", fetch_a_share_company_info()),
        ])

    if market is None or market == "HK":
        tasks.extend([
            ("æ¸¯è‚¡æ—¥Kçº¿", fetch_hk_daily_prices()),
            ("æ¸¯è‚¡åŸºæœ¬ä¿¡æ¯", fetch_hk_basic_info()),
        ])

    if market is None or market == "US":
        tasks.extend([
            ("ç¾Žè‚¡æ—¥Kçº¿", fetch_us_daily_prices()),
            ("ç¾Žè‚¡åŸºæœ¬ä¿¡æ¯", fetch_us_basic_info()),
        ])

    # Financial data (all markets)
    tasks.append(("è´¢åŠ¡æ•°æ®èŽ·å–", fetch_all_financial_data(market)))

    # Technical indicators (depends on price data)
    tasks.append(("æŠ€æœ¯æŒ‡æ ‡è®¡ç®—", calculate_all_indicators(market)))

    for task_name, coro in tasks:
        logger.info(f"\n{'â”€' * 40}")
        logger.info(f"â–¶ {task_name}")
        logger.info(f"{'â”€' * 40}")
        try:
            await coro
            logger.info(f"âœ… {task_name} å®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ {task_name} å¤±è´¥: {e}")

    elapsed = time.perf_counter() - start
    logger.info("=" * 60)
    logger.info(f"ðŸŽ‰ Pipeline å®Œæˆ! è€—æ—¶ {elapsed:.1f}s")
    logger.info("=" * 60)


def main() -> None:
    parser = argparse.ArgumentParser(description="Stock data pipeline runner")
    parser.add_argument("--market", choices=["CN", "HK", "US"], default=None, help="Target market")
    args = parser.parse_args()
    asyncio.run(run_pipeline(args.market))


if __name__ == "__main__":
    main()
