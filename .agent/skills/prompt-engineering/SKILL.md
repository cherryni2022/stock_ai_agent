---
name: prompt-engineering
description: Prompt engineering templates and patterns for the Stock AI Agent project. Use when designing or modifying prompts for intent classification, entity extraction, Text-to-SQL generation with RAG few-shot examples, analysis synthesis, response formatting, or SQL example batch generation. Triggers on any prompt template, LLM structured output, few-shot example formatting, or system/user prompt construction task.
---

# Prompt Engineering Patterns

## Prompt File Organization

All prompts live in `stock_agent/agent/prompts/` as Python string constants.

```
agent/prompts/
â”œâ”€â”€ intent.py          # INTENT_PROMPT, ENTITY_EXTRACTION_PROMPT
â”œâ”€â”€ planner.py         # DECOMPOSITION_PROMPT
â”œâ”€â”€ synthesis.py       # SYNTHESIS_PROMPT
â”œâ”€â”€ responder.py       # RESPONSE_FORMAT_PROMPT
â”œâ”€â”€ text_to_sql.py     # TEXT_TO_SQL_PROMPT, BASE_SYSTEM_PROMPT
â””â”€â”€ sql_generation.py  # CATEGORY_GUIDANCE, USER_PROMPT_TEMPLATE
```

## Intent Classification Prompt

```python
INTENT_PROMPT = """ä½ æ˜¯ä¸€ä¸ªè‚¡ç¥¨åˆ†æž AI Agent çš„æ„å›¾åˆ†ç±»å™¨ã€‚

åˆ†æžç”¨æˆ·æ¶ˆæ¯ï¼Œåˆ¤æ–­æŸ¥è¯¢æ„å›¾ç±»åˆ«å’Œæ˜¯å¦éœ€è¦æ‹†è§£ï¼š

## æ„å›¾ç±»åˆ«
- simple_query: å•è‚¡ç¥¨å•æŒ‡æ ‡ (å¦‚"èŒ…å°æœ€æ–°ä»·æ ¼")
- comparison: å¤šè‚¡ç¥¨æ¨ªå‘å¯¹æ¯” (å¦‚"å¯¹æ¯”è‹¹æžœå’Œå¾®è½¯çš„PE")
- complex_analysis: éœ€è¦å¤šæ­¥éª¤åˆ†æž (å¦‚"ç»¼åˆåˆ†æžTeslaçš„è¶‹åŠ¿å’ŒåŸºæœ¬é¢")
- conversational: é—²èŠæˆ–è·Ÿè¿› (å¦‚"ä¸Šæ¬¡è¯´çš„é‚£åªè‚¡ç¥¨å‘¢")
- text_to_sql: éœ€è‡ªå®šä¹‰SQL (å¦‚"å“ªäº›è‚¡ç¥¨ä»Šå¤©æ¶¨å¹…è¶…è¿‡5%")

## åˆ¤æ–­ requires_decomposition
- True: æ¶‰åŠå¤šä¸ªæŒ‡æ ‡/å¤šä¸ªè‚¡ç¥¨/éœ€è¦å¤šæ­¥åˆ†æž
- False: å¯ä¸€æ­¥èŽ·å–çš„ç®€å•æŸ¥è¯¢

## è¾“å‡º
è¿”å›ž JSON: {category, confidence, requires_decomposition, suggested_tools, reasoning}
"""
```

## Text-to-SQL Prompt Architecture

Text-to-SQL uses a 3-part prompt:

1. **BASE_SYSTEM_PROMPT**: Schema DDL + MVP stock pool + strict constraints
2. **CATEGORY_GUIDANCE**: Category-specific query pattern guidance
3. **Few-shot examples**: RAG-retrieved similar examples injected at runtime

For complete prompt templates, see [references/text-to-sql-prompts.md](references/text-to-sql-prompts.md).

## Synthesis Prompt Pattern

```python
SYNTHESIS_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šè‚¡ç¥¨åˆ†æžå¸ˆï¼Œè´Ÿè´£ç»¼åˆå¤šä¸ªæ•°æ®æºçš„ç»“æžœã€‚

## å·²èŽ·å–æ•°æ®
{tool_results_json}

## ç”¨æˆ·åŽŸå§‹é—®é¢˜
{user_question}

## è¦æ±‚
1. ç”¨ä¸­æ–‡å›žç­”ï¼Œè¯­è¨€ä¸“ä¸šä½†æ˜“æ‡‚
2. å¼•ç”¨å…·ä½“æ•°æ® (æ—¥æœŸã€æ•°å€¼)
3. ç»™å‡ºåˆ†æžç»“è®ºå’ŒæŠ•èµ„è§‚ç‚¹ (ä½†ä¸æž„æˆæŠ•èµ„å»ºè®®)
4. å¦‚æžœæ•°æ®ä¸è¶³ï¼Œæ˜Žç¡®è¯´æ˜Žç¼ºä»€ä¹ˆ
5. ç»“å°¾é™„é£Žé™©æç¤º

## è¾“å‡ºæ ¼å¼
markdown æ ¼å¼ï¼ŒåŒ…å«:
- ðŸ“Š æ•°æ®æ‘˜è¦ (å…³é”®æ•°å­—)
- ðŸ“ˆ åˆ†æžç»“è®º (è¶‹åŠ¿åˆ¤æ–­)
- âš ï¸ é£Žé™©æç¤º
"""
```

## LLM Structured Output Pattern

Use `with_structured_output()` for Pydantic model extraction:

```python
from langchain_core.messages import SystemMessage, HumanMessage

intent = await llm.with_structured_output(IntentClassification).ainvoke([
    SystemMessage(content=INTENT_PROMPT),
    HumanMessage(content=user_message),
])
```

## Few-shot Example Formatting

```python
def format_sql_examples(examples: list[dict]) -> str:
    """Format RAG-retrieved SQL examples for prompt injection."""
    parts = []
    for i, ex in enumerate(examples, 1):
        parts.append(f"""### ç¤ºä¾‹ {i} (ç›¸ä¼¼åº¦: {ex.get('similarity', 'N/A'):.2%})
é—®é¢˜: {ex['question']}
SQL:
```sql
{ex['sql_query']}
```
è¯´æ˜Ž: {ex.get('description', '')}
""")
    return "\n".join(parts)
```

## Key Constraints in All Prompts

1. **SQL safety**: Only SELECT. Never INSERT/UPDATE/DELETE/DROP
2. **Ticker source**: Only use tickers from MVP stock pool
3. **Field names**: Use exact DB column names (e.g., `macd_diff` not `macd`, `price_to_earnings_ratio` not `pe_ratio`)
4. **Date format**: `trade_date` is VARCHAR(10) format 'YYYY-MM-DD'
5. **Language**: All user-facing text in Chinese

## Reference Files

- **[references/text-to-sql-prompts.md](references/text-to-sql-prompts.md)**: Complete BASE_SYSTEM_PROMPT, CATEGORY_GUIDANCE for all 6 categories, and USER_PROMPT_TEMPLATE
