# Stock AI Agent æŠ€æœ¯å®ç°æ–‡æ¡£

> **ç‰ˆæœ¬**: v1.0
> **æ—¥æœŸ**: 2026-02-10
> **å…³è”æ–‡æ¡£**: [PRD äº§å“éœ€æ±‚æ–‡æ¡£](./PRD_stock_ai_agent.md) | [ç³»ç»Ÿæ¶æ„æ–‡æ¡£](./architecture.md)

---

## 1. æ¦‚è¿°

æœ¬æ–‡æ¡£åŸºäº PRD å’Œç³»ç»Ÿæ¶æ„æ–‡æ¡£ï¼Œæä¾›å„æ¨¡å—çš„è¯¦ç»†å®ç°æ–¹æ¡ˆï¼ŒåŒ…å«æ ¸å¿ƒæ•°æ®æ¨¡å‹ã€Agent ç¼–æ’ã€å·¥å…·å®ç°ã€æœåŠ¡å±‚ã€API å±‚å’Œæ•°æ®ç®¡é“çš„å…·ä½“ä»£ç è®¾è®¡ã€‚

### 1.1 ç›®å½•ç»“æ„å›é¡¾

```
stock_agent/
â”œâ”€â”€ config.py           # é…ç½®ç®¡ç†
â”œâ”€â”€ main.py             # FastAPI å…¥å£
â”œâ”€â”€ agent/              # Agent æ ¸å¿ƒ
â”‚   â”œâ”€â”€ graph.py        # LangGraph å›¾å®šä¹‰
â”‚   â”œâ”€â”€ state.py        # å…¨å±€çŠ¶æ€
â”‚   â”œâ”€â”€ nodes/          # å›¾èŠ‚ç‚¹
â”‚   â””â”€â”€ prompts/        # Prompt æ¨¡æ¿
â”œâ”€â”€ tools/              # Agent å·¥å…·
â”œâ”€â”€ database/           # æ•°æ®åº“å±‚
â”‚   â”œâ”€â”€ models/         # SQLAlchemy æ¨¡å‹
â”‚   â””â”€â”€ repositories/   # æ•°æ®è®¿é—®å±‚
â”œâ”€â”€ services/           # ä¸šåŠ¡æœåŠ¡å±‚
â””â”€â”€ api/                # API è·¯ç”±

data_pipeline/          # æ•°æ®ç®¡é“
frontend/               # å‰ç«¯
```

### 1.2 MVP å¼€å‘èŒƒå›´

> [!IMPORTANT]
> MVP å’Œå‰æœŸå¼€å‘é˜¶æ®µä»¥ **è·‘é€šæ ¸å¿ƒæµç¨‹** ä¸ºç›®æ ‡ï¼Œæ•°æ®è§„æ¨¡å’Œè‡ªåŠ¨åŒ–ç¨‹åº¦åˆ»æ„ç¼©å‡ã€‚

#### æ•°æ®æ›´æ–°ç­–ç•¥

MVP é˜¶æ®µ **ä¸éœ€è¦** å®šæ—¶ä»»åŠ¡æˆ–è‡ªåŠ¨è°ƒåº¦ã€‚æ‰€æœ‰æ•°æ®è·å–é€šè¿‡æ‰‹åŠ¨æ‰§è¡Œè„šæœ¬å®Œæˆï¼š

```bash
# æ•°æ®æ›´æ–° â€” æ‰‹åŠ¨æ‰§è¡Œ
python -m data_pipeline.akshare_fetcher        # Aè‚¡æ•°æ®
python -m data_pipeline.yfinance_fetcher        # æ¸¯è‚¡/ç¾è‚¡æ•°æ®
python -m data_pipeline.indicator_calculator    # æŠ€æœ¯æŒ‡æ ‡ (ä¾èµ–ä¸Šé¢ä¸¤æ­¥)
python -m data_pipeline.news_fetcher            # æ–°é—»è·å–
python -m data_pipeline.embedding_pipeline      # æ–°é—»å‘é‡åŒ–
python -m data_pipeline.sql_examples_seeder     # SQL ç¤ºä¾‹å‘é‡åŒ–å…¥åº“
```

#### MVP è‚¡ç¥¨æ ‡çš„æ± 

æ¯ä¸ªå¸‚åœºåªé€‰å–å°‘é‡å…·æœ‰ä»£è¡¨æ€§çš„è‚¡ç¥¨ï¼Œç¡®ä¿æ•°æ®å¯å¿«é€Ÿå‡†å¤‡ï¼ŒåŒæ—¶è¦†ç›–ä¸‰å¤§å¸‚åœºæ ¸å¿ƒåœºæ™¯ï¼š

| å¸‚åœº | è‚¡ç¥¨ | Ticker | é€‰æ‹©ç†ç”± |
|------|------|--------|----------|
| **ç¾è‚¡ (NASDAQ)** | Apple | `AAPL` | å¸‚å€¼æœ€å¤§ |
| | Microsoft | `MSFT` | äº‘+AI é¢†å†› |
| | NVIDIA | `NVDA` | AI èŠ¯ç‰‡ |
| | Alphabet (Google) | `GOOG` | æœç´¢+AI |
| | Amazon | `AMZN` | ç”µå•†+äº‘ |
| | Meta | `META` | ç¤¾äº¤+AI |
| | Tesla | `TSLA` | æ–°èƒ½æº+è‡ªåŠ¨é©¾é©¶ |
| **æ¸¯è‚¡** | é˜¿é‡Œå·´å·´ | `9988.HK` | ç”µå•†å¹³å° |
| | è…¾è®¯ | `0700.HK` | ç¤¾äº¤+æ¸¸æˆ |
| | å¿«æ‰‹ | `1024.HK` | çŸ­è§†é¢‘+AI |
| **Aè‚¡** | èµ›åŠ›æ–¯ | `601127` | æ–°èƒ½æºæ±½è½¦ |
| | ä¸­èŠ¯å›½é™… | `688981` | åŠå¯¼ä½“ |

å…±è®¡ **12 æ”¯è‚¡ç¥¨**ï¼Œæ•°æ®é‡ï¼š
- æ—¥Kçº¿ (1å¹´): ~12 Ã— 250 â‰ˆ 3,000 è¡Œ
- æŠ€æœ¯æŒ‡æ ‡ (6è¡¨): ~18,000 è¡Œ
- æ–°é—» (~100æ¡/è‚¡): ~1,200 æ¡

#### MVP æ ‡çš„æ± é…ç½®

```python
# config.py ä¸­æ·»åŠ  MVP æ ‡çš„æ± 
MVP_STOCK_UNIVERSE: dict[str, list[str]] = {
    "US": ["AAPL", "MSFT", "NVDA", "GOOG", "AMZN", "META", "TSLA"],
    "HK": ["9988.HK", "0700.HK", "1024.HK"],
    "CN": ["601127", "688981"],
}
```

---

## 2. é…ç½®ç®¡ç† (`config.py`)

ä½¿ç”¨ Pydantic Settings ç®¡ç†æ‰€æœ‰é…ç½®ï¼Œæ”¯æŒ `.env` æ–‡ä»¶å’Œç¯å¢ƒå˜é‡ã€‚

```python
from pydantic_settings import BaseSettings
from functools import lru_cache


class Settings(BaseSettings):
    """åº”ç”¨é…ç½® â€” æ‰€æœ‰å€¼é€šè¿‡ç¯å¢ƒå˜é‡æ³¨å…¥"""
    
    # ---- LLM Provider ----
    LLM_PROVIDER: str = "openai"          # openai | gemini | zhipu
    LLM_BASE_URL: str | None = None       # å¯é€‰è‡ªå®šä¹‰ç«¯ç‚¹
    LLM_API_KEY: str
    LLM_MODEL: str = "gpt-4o"
    LLM_TEMPERATURE: float = 0.1          # Agent åœºæ™¯å»ºè®®ä½æ¸©åº¦
    LLM_MAX_TOKENS: int = 4096
    
    # ---- Embedding Provider ----
    EMBEDDING_PROVIDER: str = "openai"    # openai | gemini | zhipu
    EMBEDDING_BASE_URL: str | None = None
    EMBEDDING_API_KEY: str
    EMBEDDING_MODEL: str = "text-embedding-3-small"
    EMBEDDING_DIMENSIONS: int = 1536      # ç»Ÿä¸€ç»´åº¦
    
    # ---- Supabase ----
    SUPABASE_URL: str
    SUPABASE_KEY: str
    SUPABASE_DB_URL: str                  # postgresql://...
    
    # ---- Application ----
    APP_ENV: str = "development"
    LOG_LEVEL: str = "INFO"
    MAX_RETRIES: int = 3
    TOOL_TIMEOUT_SECONDS: int = 30
    MAX_SUB_TASKS: int = 10               # å•æ¬¡é—®é¢˜æœ€å¤§å­ä»»åŠ¡æ•°
    RAG_TOP_K: int = 10                   # RAG æ£€ç´¢è¿”å›æ•°
    SQL_MAX_ROWS: int = 500               # SQL æŸ¥è¯¢è¡Œæ•°é™åˆ¶
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"


@lru_cache
def get_settings() -> Settings:
    return Settings()
```

---

## 3. æ ¸å¿ƒæ•°æ®æ¨¡å‹

### 3.1 Agent çŠ¶æ€æ¨¡å‹ (`agent/state.py`)

```python
from typing import Annotated, Any
from typing_extensions import TypedDict
from langgraph.graph.message import add_messages
from langchain_core.messages import BaseMessage
from pydantic import BaseModel, Field
from enum import Enum


# ---- æ„å›¾åˆ†ç±» ----

class IntentCategory(str, Enum):
    """6 å¤§æ„å›¾ç±»åˆ«"""
    SIMPLE_QUERY = "simple_query"           # ç®€å•äº‹å®æŸ¥è¯¢
    TECHNICAL_ANALYSIS = "technical_analysis" # æŠ€æœ¯åˆ†æ
    FINANCIAL_ANALYSIS = "financial_analysis" # è´¢åŠ¡åˆ†æ
    NEWS_SENTIMENT = "news_sentiment"         # æ–°é—»èˆ†æƒ…
    COMPOSITE = "composite"                   # ç»¼åˆåˆ†æ
    COMPARISON = "comparison"                 # å¯¹æ¯”åˆ†æ


class IntentClassification(BaseModel):
    """LLM ç»“æ„åŒ–è¾“å‡ºçš„æ„å›¾åˆ†ç±»ç»“æœ"""
    category: IntentCategory
    confidence: float = Field(ge=0, le=1)
    reasoning: str                            # LLM åˆ†ç±»ç†ç”±
    requires_decomposition: bool = False       # æ˜¯å¦éœ€è¦é—®é¢˜æ‹†è§£
    suggested_tools: list[str] = []            # å»ºè®®ä½¿ç”¨çš„å·¥å…·


# ---- å®ä½“æå– ----

class MarketType(str, Enum):
    CN = "CN"     # Aè‚¡
    HK = "HK"     # æ¸¯è‚¡
    US = "US"     # ç¾è‚¡


class StockEntity(BaseModel):
    """è§£æåçš„è‚¡ç¥¨å®ä½“"""
    name: str                  # è‚¡ç¥¨åç§° (å¦‚ "è´µå·èŒ…å°")
    ticker: str                # æ ‡å‡†ä»£ç  (å¦‚ "600519")
    market: MarketType         # å¸‚åœº
    raw_input: str = ""        # ç”¨æˆ·åŸå§‹è¾“å…¥ (å¦‚ "èŒ…å°")


class TimeRange(BaseModel):
    """æ—¶é—´èŒƒå›´"""
    start_date: str | None = None  # YYYY-MM-DD
    end_date: str | None = None
    relative: str | None = None     # "æœ€è¿‘30å¤©", "ä»Šå¹´" ç­‰


class ExtractedEntities(BaseModel):
    """ä»ç”¨æˆ·é—®é¢˜ä¸­æå–çš„å…¨éƒ¨å®ä½“"""
    stocks: list[StockEntity] = []
    time_range: TimeRange | None = None
    indicators: list[str] = []        # æŠ€æœ¯æŒ‡æ ‡å (MACD, RSI)
    financial_metrics: list[str] = []  # è´¢åŠ¡æŒ‡æ ‡å (PE, ROE)
    comparison_targets: list[str] = []
    keywords: list[str] = []           # æ–°é—»æ£€ç´¢å…³é”®è¯


# ---- æ‰§è¡Œè®¡åˆ’ ----

class TaskStatus(str, Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"


class SubTask(BaseModel):
    """å­ä»»åŠ¡"""
    task_id: str
    description: str
    tool_name: str
    tool_params: dict[str, Any] = {}
    dependencies: list[str] = []
    status: TaskStatus = TaskStatus.PENDING
    result: Any | None = None
    error: str | None = None
    duration_ms: int | None = None


class DecompositionPlan(BaseModel):
    """é—®é¢˜æ‹†è§£æ‰§è¡Œè®¡åˆ’"""
    original_question: str
    tasks: list[SubTask]
    execution_order: list[list[str]]  # [[å¹¶è¡Œå±‚1 task_ids], [å¹¶è¡Œå±‚2], ...]


# ---- LangGraph å…¨å±€çŠ¶æ€ ----

class AgentState(TypedDict):
    """LangGraph çŠ¶æ€å®šä¹‰"""
    # å¯¹è¯ä¸Šä¸‹æ–‡
    session_id: str
    user_id: str
    messages: Annotated[list[BaseMessage], add_messages]
    
    # æ„å›¾ç†è§£ç»“æœ
    intent: IntentClassification | None
    entities: ExtractedEntities | None
    resolved_stocks: list[StockEntity]
    
    # æ‰§è¡Œè®¡åˆ’
    plan: DecompositionPlan | None
    current_layer: int               # å½“å‰æ‰§è¡Œåˆ°ç¬¬å‡ å±‚
    
    # å·¥å…·æ‰§è¡Œç»“æœ
    tool_results: dict[str, Any]     # task_id â†’ result
    
    # SSE çŠ¶æ€æ¨é€å›è°ƒ
    status_callback: Any             # async callable for SSE
    
    # æœ€ç»ˆè¾“å‡º
    analysis_result: str
    data_sources: list[str]
    risk_disclaimer: str
```

### 3.2 æ•°æ®åº“æ¨¡å‹ (`database/models/`)

> [!NOTE]
> ç°æœ‰ç»“æ„åŒ–æ•°æ®æ¨¡å‹å®šä¹‰äº `PRPs/models/`ï¼ŒæŒ‰å¸‚åœºæ‹†åˆ†ä¸º 3 ä¸ªæ–‡ä»¶ï¼š
> - [stock_data_db_model.py](file:///Users/niwen/PycharmProjects/my_dev_agent/stock-ai-agent/PRPs/models/stock_data_db_model.py) â€” Aè‚¡ + é€šç”¨
> - [stock_data_db_model_hk.py](file:///Users/niwen/PycharmProjects/my_dev_agent/stock-ai-agent/PRPs/models/stock_data_db_model_hk.py) â€” æ¸¯è‚¡
> - [stock_data_db_model_us.py](file:///Users/niwen/PycharmProjects/my_dev_agent/stock-ai-agent/PRPs/models/stock_data_db_model_us.py) â€” ç¾è‚¡

#### 3.2.1 æ•°æ®æ¨¡å‹å…¨æ™¯å›¾

```mermaid
erDiagram
    stock_basic_info ||--o{ stock_daily_price : "ticker"
    stock_basic_info ||--o{ financial_metrics : "ticker"
    stock_basic_info ||--o{ stock_company_info : "ticker"
    stock_daily_price ||--o{ stock_technical_indicators : "ticker + trade_date"
    stock_daily_price ||--o{ stock_technical_trend_signal_indicators : "ticker + trade_date"
    stock_daily_price ||--o{ stock_technical_mean_reversion_signal_indicators : "ticker + trade_date"
    stock_daily_price ||--o{ stock_technical_momentum_signal_indicators : "ticker + trade_date"
    stock_daily_price ||--o{ stock_technical_volatility_signal_indicators : "ticker + trade_date"
    stock_daily_price ||--o{ stock_technical_stat_arb_signal_indicators : "ticker + trade_date"

    stock_basic_info {
        string ticker PK "è‚¡ç¥¨ä»£ç "
        string stock_name "è‚¡ç¥¨ç®€ç§°"
        string market "å¸‚åœº"
        string industry "è¡Œä¸š"
        float total_market_value "æ€»å¸‚å€¼"
    }
    stock_daily_price {
        int id PK
        string ticker FK "è‚¡ç¥¨ä»£ç "
        string trade_date UK "äº¤æ˜“æ—¥æœŸ (YYYY-MM-DD)"
        float open "å¼€ç›˜ä»·"
        float close "æ”¶ç›˜ä»·"
        float high "æœ€é«˜ä»·"
        float low "æœ€ä½ä»·"
        int volume "æˆäº¤é‡"
    }
    stock_technical_indicators {
        int id PK
        string ticker FK
        string trade_date UK
        float macd_diff "MACD_DIFF"
        float macd_dea "MACD_DEA"
        float rsi_6 "RSI(6)"
        float boll_upper "å¸ƒæ—å¸¦ä¸Šè½¨"
    }
    financial_metrics {
        int id PK
        string ticker FK
        string report_period "æŠ¥å‘ŠæœŸ"
        string period "Q1/Q2/Q3/Q4/FY"
        float price_to_earnings_ratio "PE"
        float return_on_equity "ROE"
    }
```

#### 3.2.2 ç»“æ„åŒ–æ•°æ®è¡¨æ€»è§ˆ

ç³»ç»Ÿå…±æœ‰ **11 ç±»ç»“æ„åŒ–è¡¨**ï¼Œæ¯ç±»æŒ‰å¸‚åœºæ‹†åˆ†ä¸º Aè‚¡/æ¸¯è‚¡/ç¾è‚¡ 3 å¼ è¡¨ (å‘½ååç¼€: æ— åç¼€=Aè‚¡, `_hk`, `_us`)ã€‚

| # | è¡¨å (Aè‚¡) | è¡¨å (æ¸¯è‚¡) | è¡¨å (ç¾è‚¡) | è¯´æ˜ | è”åˆå”¯ä¸€é”® |
|---|-----------|-----------|-----------|------|-----------|
| 1 | `stock_daily_price` | `stock_daily_price_hk` | `stock_daily_price_us` | æ—¥Kçº¿è¡Œæƒ… | ticker + trade_date |
| 2 | `stock_technical_indicators` | `stock_technical_indicators_hk` | `stock_technical_indicators_us` | åŸºæœ¬æŠ€æœ¯æŒ‡æ ‡ | ticker + trade_date |
| 3 | `stock_technical_trend_signal_indicators` | `..._hk` | `..._us` | è¶‹åŠ¿è·Ÿè¸ªç­–ç•¥ä¿¡å· | ticker + trade_date |
| 4 | `stock_technical_mean_reversion_signal_indicators` | `..._hk` | `..._us` | å‡å€¼å›å½’ç­–ç•¥ä¿¡å· | ticker + trade_date |
| 5 | `stock_technical_momentum_signal_indicators` | `..._hk` | `..._us` | åŠ¨é‡ç­–ç•¥ä¿¡å· | ticker + trade_date |
| 6 | `stock_technical_volatility_signal_indicators` | `..._hk` | `..._us` | æ³¢åŠ¨ç‡ç­–ç•¥ä¿¡å· | ticker + trade_date |
| 7 | `stock_technical_stat_arb_signal_indicators` | `..._hk` | `..._us` | ç»Ÿè®¡å¥—åˆ©ç­–ç•¥ä¿¡å· | ticker + trade_date |
| 8 | `financial_metrics` | `financial_metrics_hk` | `financial_metrics_us` | è´¢åŠ¡æŒ‡æ ‡ | ticker + report_period + period |
| 9 | `stock_basic_info` | `stock_basic_hk` | `stock_basic_us` | è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ | ticker |
| 10 | `stock_basic_info_a` | â€” | â€” | Aè‚¡é¢å¤–åŸºæœ¬ä¿¡æ¯ | ticker |
| 11 | `stock_company_info` | â€” | â€” | Aè‚¡å…¬å¸è¯¦ç»†ä¿¡æ¯ | ticker |
| 12 | â€” | `stock_index_basic_hk` | `stock_index_basic_us` | æŒ‡æ•°åŸºæœ¬ä¿¡æ¯ | ticker |

#### 3.2.3 å„è¡¨è¯¦ç»†å­—æ®µ

##### ğŸ“Š æ—¥Kçº¿è¡Œæƒ…è¡¨ (`stock_daily_price` / `_hk` / `_us`)

```python
class StockDailyPriceDB(Base):
    __tablename__ = "stock_daily_price"

    id          = Column(Integer, primary_key=True, autoincrement=True)
    ticker      = Column(String(10), nullable=False, index=True, comment="è‚¡ç¥¨ä»£ç ")
    symbol      = Column(String(20), comment="è‚¡ç¥¨ä»£ç ï¼ˆå«å¸‚åœºæ ‡è¯†ï¼‰")
    name        = Column(String(50), index=True, comment="è‚¡ç¥¨åç§°")
    trade_date  = Column(String(10), index=True, comment="äº¤æ˜“æ—¥æœŸ (YYYY-MM-DD)")
    open        = Column(Float, comment="å¼€ç›˜ä»·")
    high        = Column(Float, comment="æœ€é«˜ä»·")
    low         = Column(Float, comment="æœ€ä½ä»·")
    close       = Column(Float, comment="æ”¶ç›˜ä»·")
    volume      = Column(Integer, comment="æˆäº¤é‡")
    amount      = Column(Float, comment="æˆäº¤é¢")
    amplitude   = Column(Float, comment="æŒ¯å¹…")
    pct_change  = Column(Float, comment="æ¶¨è·Œå¹…")
    amount_change = Column(Float, comment="æ¶¨è·Œé¢")
    turnover_rate = Column(Float, comment="æ¢æ‰‹ç‡")
    created_at  = Column(DateTime)
    updated_at  = Column(DateTime)

    __table_args__ = (
        UniqueConstraint('ticker', 'trade_date', name='uq_stock_daily_ticker_date'),
    )
```

##### ğŸ“ˆ åŸºæœ¬æŠ€æœ¯æŒ‡æ ‡è¡¨ (`stock_technical_indicators` / `_hk` / `_us`)

```python
class StockTechnicalIndicatorsDB(Base):
    __tablename__ = "stock_technical_indicators"
    __table_args__ = {'comment': 'è‚¡ç¥¨åŸºæœ¬æŠ€æœ¯æŒ‡æ ‡æ•°æ®è¡¨'}

    id          = Column(Integer, primary_key=True, autoincrement=True)
    ticker      = Column(String(10), nullable=False, index=True, comment="è‚¡ç¥¨ä»£ç ")
    symbol      = Column(String(20), comment="è‚¡ç¥¨ä»£ç ï¼ˆå«å¸‚åœºæ ‡è¯†ï¼‰")
    name        = Column(String(50), index=True, comment="è‚¡ç¥¨åç§°")
    trade_date  = Column(String(10), index=True, comment="äº¤æ˜“æ—¥æœŸ")
    # ç§»åŠ¨å‡çº¿
    ma5         = Column(Float, comment="5æ—¥å‡çº¿")
    ma10        = Column(Float, comment="10æ—¥å‡çº¿")
    ma20        = Column(Float, comment="20æ—¥å‡çº¿")
    ma30        = Column(Float, comment="30æ—¥å‡çº¿")
    ma60        = Column(Float, comment="60æ—¥å‡çº¿")
    # å¸ƒæ—å¸¦
    boll_upper  = Column(Float, comment="å¸ƒæ—å¸¦ä¸Šè½¨")
    boll_middle = Column(Float, comment="å¸ƒæ—å¸¦ä¸­è½¨")
    boll_lower  = Column(Float, comment="å¸ƒæ—å¸¦ä¸‹è½¨")
    # KDJ
    kdj_k       = Column(Float, comment="KDJ-Kå€¼")
    kdj_d       = Column(Float, comment="KDJ-Då€¼")
    kdj_j       = Column(Float, comment="KDJ-Jå€¼")
    # RSI
    rsi_6       = Column(Float, comment="6æ—¥RSI")
    rsi_12      = Column(Float, comment="12æ—¥RSI")
    rsi_24      = Column(Float, comment="24æ—¥RSI")
    # MACD
    macd_diff   = Column(Float, comment="MACD_DIFF")
    macd_dea    = Column(Float, comment="MACD_DEA")
    macd_hist   = Column(Float, comment="MACDæŸ±çŠ¶å›¾")

    __table_args__ = (
        UniqueConstraint('ticker', 'trade_date', name='uq_stock_tech_ind_ticker_date'),
    )
```

##### ğŸ¯ ç­–ç•¥ä¿¡å·è¡¨ç»„ (5 å¼ )

5 å¼ ç­–ç•¥ä¿¡å·è¡¨ç»“æ„ç›¸ä¼¼ï¼Œå‡ä»¥ `ticker + trade_date` ä¸ºè”åˆå”¯ä¸€é”®ã€‚ä»¥ä¸‹åˆ—å‡ºæ¯å¼ è¡¨çš„**ç‰¹æœ‰å­—æ®µ**ï¼š

| è¡¨å | ä¿¡å·å­—æ®µ | ç½®ä¿¡åº¦å­—æ®µ | æ ¸å¿ƒæŒ‡æ ‡å­—æ®µ |
|------|---------|-----------|-------------|
| **è¶‹åŠ¿è·Ÿè¸ª** `stock_technical_trend_signal_indicators` | `trend_signal` (bullish/bearish/neutral) | `trend_confidence` | `ema_8`, `ema_21`, `ema_55`, `adx`, `plus_di`, `minus_di`, `short_trend` (bool), `medium_trend` (bool), `trend_strength` |
| **å‡å€¼å›å½’** `stock_technical_mean_reversion_signal_indicators` | `mean_reversion_signal` | `mean_reversion_confidence` | `ma_50`, `std_50`, `z_score`, `bb_upper`, `bb_middle`, `bb_lower`, `rsi_14`, `rsi_28`, `price_vs_bb` |
| **åŠ¨é‡** `stock_technical_momentum_signal_indicators` | `momentum_signal` | `momentum_confidence` | `returns`, `mom_1m`, `mom_3m`, `mom_6m`, `volume_ma_21`, `volume_momentum`, `momentum_score`, `volume_confirmation` (bool) |
| **æ³¢åŠ¨ç‡** `stock_technical_volatility_signal_indicators` | `volatility_signal` | `volatility_confidence` | `returns`, `hist_vol_21`, `vol_ma_63`, `vol_regime`, `vol_std_63`, `vol_z_score`, `atr_14`, `atr_ratio` |
| **ç»Ÿè®¡å¥—åˆ©** `stock_technical_stat_arb_signal_indicators` | `stat_arb_signal` | `stat_arb_confidence` | `returns`, `skew_63`, `kurt_63`, `hurst_exponent` |

æ¯å¼ è¡¨çš„é€šç”¨å­—æ®µ (çœç•¥ä¸é‡å¤):

```python
# æ¯å¼ ç­–ç•¥ä¿¡å·è¡¨éƒ½åŒ…å«ä»¥ä¸‹é€šç”¨å­—æ®µ
id          = Column(Integer, primary_key=True, autoincrement=True)
ticker      = Column(String(10), nullable=False, index=True, comment="è‚¡ç¥¨ä»£ç ")
symbol      = Column(String(20), comment="è‚¡ç¥¨ä»£ç ï¼ˆå«å¸‚åœºæ ‡è¯†ï¼‰")
name        = Column(String(50), index=True, comment="è‚¡ç¥¨åç§°")
trade_date  = Column(String(10), index=True, comment="äº¤æ˜“æ—¥æœŸ")
# ... (å„ç­–ç•¥ç‰¹æœ‰å­—æ®µè§ä¸Šè¡¨) ...
created_at  = Column(DateTime)
updated_at  = Column(DateTime)
```

##### ğŸ’° è´¢åŠ¡æŒ‡æ ‡è¡¨ (`financial_metrics` / `_hk` / `_us`)

```python
class FinancialMetricsDB(Base):
    __tablename__ = "financial_metrics"

    id             = Column(Integer, primary_key=True, autoincrement=True)
    ticker         = Column(String(20), nullable=False, index=True, comment="è‚¡ç¥¨ä»£ç ")
    report_period  = Column(String(20), nullable=False, comment="æŠ¥å‘ŠæœŸ")
    period         = Column(String(10), nullable=False, comment="Q1/Q2/Q3/Q4/H1/H2/FY")
    currency       = Column(String(10), comment="è´§å¸ç±»å‹ (CNY/USD)")

    # ---- å¸‚åœºä¼°å€¼ ----
    market_cap                      = Column(Float, comment="å¸‚å€¼")
    enterprise_value                = Column(Float, comment="ä¼ä¸šä»·å€¼")
    price_to_earnings_ratio         = Column(Float, comment="å¸‚ç›ˆç‡ (P/E)")
    price_to_book_ratio             = Column(Float, comment="å¸‚å‡€ç‡ (P/B)")
    price_to_sales_ratio            = Column(Float, comment="å¸‚é”€ç‡ (P/S)")
    enterprise_value_to_ebitda_ratio = Column(Float, comment="EV/EBITDA")
    enterprise_value_to_revenue_ratio = Column(Float, comment="EV/Revenue")
    free_cash_flow_yield            = Column(Float, comment="è‡ªç”±ç°é‡‘æµæ”¶ç›Šç‡")
    peg_ratio                       = Column(Float, comment="PEGæ¯”ç‡")

    # ---- ç›ˆåˆ©èƒ½åŠ› ----
    gross_margin     = Column(Float, comment="æ¯›åˆ©ç‡")
    operating_margin = Column(Float, comment="è¥ä¸šåˆ©æ¶¦ç‡")
    net_margin       = Column(Float, comment="å‡€åˆ©ç‡")

    # ---- å›æŠ¥ç‡ ----
    return_on_equity            = Column(Float, comment="ROE")
    return_on_assets            = Column(Float, comment="ROA")
    return_on_invested_capital  = Column(Float, comment="ROIC")

    # ---- è¿è¥æ•ˆç‡ ----
    asset_turnover          = Column(Float, comment="èµ„äº§å‘¨è½¬ç‡")
    inventory_turnover      = Column(Float, comment="å­˜è´§å‘¨è½¬ç‡")
    receivables_turnover    = Column(Float, comment="åº”æ”¶è´¦æ¬¾å‘¨è½¬ç‡")
    days_sales_outstanding  = Column(Float, comment="åº”æ”¶è´¦æ¬¾å‘¨è½¬å¤©æ•°")
    operating_cycle         = Column(Float, comment="è¥ä¸šå‘¨æœŸ")
    working_capital_turnover = Column(Float, comment="è¥è¿èµ„æœ¬å‘¨è½¬ç‡")

    # ---- æµåŠ¨æ€§ ----
    current_ratio           = Column(Float, comment="æµåŠ¨æ¯”ç‡")
    quick_ratio             = Column(Float, comment="é€ŸåŠ¨æ¯”ç‡")
    cash_ratio              = Column(Float, comment="ç°é‡‘æ¯”ç‡")
    operating_cash_flow_ratio = Column(Float, comment="ç»è¥ç°é‡‘æµæ¯”ç‡")

    # ---- è´Ÿå€º ----
    debt_to_equity    = Column(Float, comment="èµ„äº§è´Ÿå€ºç‡")
    debt_to_assets    = Column(Float, comment="å€ºåŠ¡èµ„äº§æ¯”")
    interest_coverage = Column(Float, comment="åˆ©æ¯è¦†ç›–ç‡")

    # ---- å¢é•¿ ----
    revenue_growth          = Column(Float, comment="æ”¶å…¥å¢é•¿ç‡")
    earnings_growth         = Column(Float, comment="ç›ˆåˆ©å¢é•¿ç‡")
    book_value_growth       = Column(Float, comment="è´¦é¢ä»·å€¼å¢é•¿ç‡")
    earnings_per_share_growth = Column(Float, comment="EPSå¢é•¿ç‡")
    free_cash_flow_growth   = Column(Float, comment="FCFå¢é•¿ç‡")
    operating_income_growth = Column(Float, comment="è¥ä¸šæ”¶å…¥å¢é•¿ç‡")
    ebitda_growth           = Column(Float, comment="EBITDAå¢é•¿ç‡")

    # ---- æ¯è‚¡æŒ‡æ ‡ ----
    payout_ratio            = Column(Float, comment="æ´¾æ¯æ¯”ç‡")
    earnings_per_share      = Column(Float, comment="æ¯è‚¡æ”¶ç›Š (EPS)")
    book_value_per_share    = Column(Float, comment="æ¯è‚¡è´¦é¢ä»·å€¼")
    free_cash_flow_per_share = Column(Float, comment="æ¯è‚¡è‡ªç”±ç°é‡‘æµ")

    __table_args__ = (
        UniqueConstraint('ticker', 'report_period', 'period',
                         name='uq_financial_metrics_ticker_report_period'),
    )
```

##### ğŸ·ï¸ åŸºæœ¬ä¿¡æ¯è¡¨ç»„

**`stock_basic_info`** â€” é€šç”¨è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ (Aè‚¡é€šè¿‡ akshare è·å–):

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `ticker` (PK) | String(20) | è‚¡ç¥¨ä»£ç  |
| `stock_name` | String(100) | è‚¡ç¥¨ç®€ç§° |
| `total_shares` | Float | æ€»è‚¡æœ¬ |
| `float_shares` | Float | æµé€šè‚¡ |
| `total_market_value` | Float | æ€»å¸‚å€¼ |
| `float_market_value` | Float | æµé€šå¸‚å€¼ |
| `industry` | String(100) | è¡Œä¸š |
| `listing_date` | String(20) | ä¸Šå¸‚æ—¶é—´ |
| `latest_price` | Float | æœ€æ–°è‚¡ä»· |

**`stock_basic_info_a`** â€” Aè‚¡é¢å¤–åŸºæœ¬ä¿¡æ¯:

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `ticker` (PK) | String(10) | è‚¡ç¥¨ä»£ç  |
| `symbol` | String(10) | ä¸å«å¸‚åœºæ ‡è¯†çš„ä»£ç  |
| `name` | String(50) | è‚¡ç¥¨åç§° |
| `area` | String(50) | åœ°åŒº |
| `industry` | String(50) | æ‰€å±è¡Œä¸š |
| `fullname` | String(100) | è‚¡ç¥¨å…¨ç§° |
| `enname` | String(100) | è‹±æ–‡åç§° |
| `market` | String(20) | å¸‚åœºç±»å‹ |
| `exchange` | String(20) | äº¤æ˜“æ‰€ |
| `list_status` | String(1) | ä¸Šå¸‚çŠ¶æ€ (L/D/P) |
| `list_date` | String(10) | ä¸Šå¸‚æ—¥æœŸ |
| `is_hs` | String(1) | æ˜¯å¦æ²ªæ·±æ¸¯é€šæ ‡çš„ |
| `act_name` | String(100) | å®é™…æ§åˆ¶äººåç§° |

**`stock_company_info`** â€” Aè‚¡å…¬å¸è¯¦ç»†ä¿¡æ¯:

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `ticker` (PK) | String(20) | Aè‚¡ä»£ç  |
| `company_name` | String(255) | å…¬å¸åç§° |
| `english_name` | String(255) | è‹±æ–‡åç§° |
| `a_share_abbreviation` | String(100) | Aè‚¡ç®€ç§° |
| `b_share_code` / `h_share_code` | String(20) | B/Hè‚¡ä»£ç  |
| `selected_index` | Text | å…¥é€‰æŒ‡æ•° |
| `market` | String(50) | æ‰€å±å¸‚åœº |
| `industry` | String(100) | æ‰€å±è¡Œä¸š |
| `legal_representative` | String(100) | æ³•äººä»£è¡¨ |
| `registered_capital` | String(100) | æ³¨å†Œèµ„é‡‘ |
| `establishment_date` | String(20) | æˆç«‹æ—¥æœŸ |
| `official_website` | String(255) | å®˜æ–¹ç½‘ç«™ |

**`stock_basic_hk` / `stock_basic_us`** â€” æ¸¯è‚¡/ç¾è‚¡åŸºæœ¬ä¿¡æ¯ (é€šè¿‡ yfinance è·å–):

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `ticker` (PK) | String(20) | è‚¡ç¥¨ä»£ç  |
| `short_name` | String(100) | ç®€ç§° |
| `long_name` | String(255) | å…¨ç§° |
| `exchange` | String(20) | äº¤æ˜“æ‰€ |
| `market` | String(20) | å¸‚åœº |
| `currency` | String(10) | äº¤æ˜“è´§å¸ |
| `sector` | String(100) | è¡Œä¸šæ¿å— |
| `industry` | String(200) | ç»†åˆ†è¡Œä¸š |
| `market_cap` | Float | å¸‚å€¼ |
| `float_shares` | Float | æµé€šè‚¡ |
| `dividend_yield` | Float | è‚¡æ¯ç‡ |
| `beta` | Float | Betaç³»æ•° |
| `pe_trailing` / `pe_forward` | Float | å†å²PE / è¿œæœŸPE |
| `country` | String(50) | å›½å®¶ |
| `website` | String(255) | å®˜ç½‘ |
| `logo_url` | String(500) | Logo URL |
| `long_business_summary` | Text | å…¬å¸ä¸šåŠ¡æè¿° |

##### ğŸ“‹ æŒ‡æ•°ä¿¡æ¯è¡¨ (`stock_index_basic_hk` / `_us`)

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `id` (PK) | Integer | è‡ªå¢ä¸»é”® |
| `ticker` | String | æŒ‡æ•°ä»£ç  |
| `name` | String | æŒ‡æ•°åç§° |
| `full_name` | String | æŒ‡æ•°å…¨ç§° |
| `market` | String | å¸‚åœº |
| `publisher` | String | å‘å¸ƒæ–¹ |
| `index_type` | String | æŒ‡æ•°ç±»å‹ |
| `category` | String | æŒ‡æ•°ç±»åˆ« |
| `base_date` | String | åŸºæœŸ |
| `base_point` | Float | åŸºç‚¹ |
| `list_date` | String | å‘å¸ƒæ—¥æœŸ |
| `weight_rule` | String | åŠ æƒè§„åˆ™ |
| `desc` | String | æŒ‡æ•°æè¿° |

#### 3.2.4 è¡¨å‘½åçº¦å®š & çº¦æŸç­–ç•¥

| ç»´åº¦ | è§„åˆ™ |
|------|------|
| **è¡¨å** | `{åŠŸèƒ½}_{å¸‚åœºåç¼€}` â€” æ— åç¼€=Aè‚¡, `_hk`=æ¸¯è‚¡, `_us`=ç¾è‚¡ |
| **ä¸»é”®** | è‡ªå¢ `id` (è¡Œæƒ…/æŒ‡æ ‡/è´¢åŠ¡) æˆ– `ticker` (åŸºæœ¬ä¿¡æ¯) |
| **å”¯ä¸€çº¦æŸ** | `ticker + trade_date` æˆ– `ticker + report_period + period` |
| **ç´¢å¼•** | `ticker`, `trade_date` å„è‡ªç‹¬ç«‹ç´¢å¼• + è”åˆå”¯ä¸€çº¦æŸ |
| **æ—¶é—´æˆ³** | æ‰€æœ‰è¡¨åŒ…å« `created_at` + `updated_at` |
| **trade_date ç±»å‹** | `VARCHAR(10)`, æ ¼å¼ `'YYYY-MM-DD'` (âš ï¸ é DATE ç±»å‹) |

> [!WARNING]
> å½“å‰å„å¸‚åœºè¡¨ç»“æ„å®Œå…¨ç›¸åŒä½†ç‹¬ç«‹å­˜å‚¨ã€‚åç»­å¯è€ƒè™‘ç»Ÿä¸€ä¸ºå•è¡¨ + `market` å­—æ®µçš„è®¾è®¡ (å‚è§ Conversation `7c2bfe41` ä¸­è®¨è®ºçš„ unified schema)ã€‚

#### 3.2.5 æ–°å¢æ¨¡å‹: ç”¨æˆ·/ä¼šè¯/æ—¥å¿—



```python
# database/models/user.py
from sqlalchemy import Column, String, Text, DateTime, ForeignKey, Integer, JSON
from sqlalchemy.dialects.postgresql import UUID, JSONB
from sqlalchemy.orm import relationship
import uuid
from datetime import datetime, timezone
from .base import Base


class User(Base):
    __tablename__ = "users"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    username = Column(String(50), unique=True, nullable=False)
    email = Column(String(255), unique=True)
    display_name = Column(String(100))
    avatar_url = Column(Text)
    preferences = Column(JSONB, default={})
    created_at = Column(DateTime(timezone=True), default=lambda: datetime.now(timezone.utc))
    updated_at = Column(DateTime(timezone=True), onupdate=lambda: datetime.now(timezone.utc))
    
    sessions = relationship("ChatSession", back_populates="user")


class ChatSession(Base):
    __tablename__ = "chat_sessions"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"), nullable=False)
    title = Column(String(255))
    summary = Column(Text)
    status = Column(String(20), default="active")
    metadata_ = Column("metadata", JSONB, default={})
    created_at = Column(DateTime(timezone=True), default=lambda: datetime.now(timezone.utc))
    updated_at = Column(DateTime(timezone=True), onupdate=lambda: datetime.now(timezone.utc))
    
    user = relationship("User", back_populates="sessions")
    messages = relationship("ChatMessage", back_populates="session", order_by="ChatMessage.created_at")


class ChatMessage(Base):
    __tablename__ = "chat_messages"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    session_id = Column(UUID(as_uuid=True), ForeignKey("chat_sessions.id"), nullable=False)
    role = Column(String(20), nullable=False)       # user / assistant / system / tool
    content = Column(Text, nullable=False)
    metadata_ = Column("metadata", JSONB, default={})
    parent_message_id = Column(UUID(as_uuid=True))
    created_at = Column(DateTime(timezone=True), default=lambda: datetime.now(timezone.utc))
    
    session = relationship("ChatSession", back_populates="messages")
```

```python
# database/models/agent_log.py
class AgentExecutionLog(Base):
    __tablename__ = "agent_execution_log"
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("chat_sessions.id"), nullable=False)
    message_id = Column(UUID(as_uuid=True), ForeignKey("chat_messages.id"), nullable=False)
    step_name = Column(String(100), nullable=False)
    step_order = Column(Integer)
    status = Column(String(20), nullable=False)
    input_data = Column(JSONB)
    output_data = Column(JSONB)
    error_message = Column(Text)
    duration_ms = Column(Integer)
    llm_tokens_used = Column(JSONB)   # {prompt_tokens, completion_tokens, total_tokens}
    started_at = Column(DateTime(timezone=True))
    completed_at = Column(DateTime(timezone=True))
    created_at = Column(DateTime(timezone=True), default=lambda: datetime.now(timezone.utc))
```

### 3.3 å‘é‡æ•°æ®æ¨¡å‹ (`database/models/vector.py`)

ç³»ç»Ÿä¸­æœ‰ **3 ç±»ä¿¡æ¯** éœ€è¦å‘é‡åŒ–å­˜å‚¨ï¼Œç”¨äºä¸åŒçš„ RAG åœºæ™¯ã€‚ä»¥ä¸‹æ˜¯æ¯å¼ å‘é‡è¡¨çš„è¯¦ç»†è®¾è®¡ã€‚

#### éœ€è¦å‘é‡åŒ–çš„ä¿¡æ¯ä¸€è§ˆ

| å‘é‡è¡¨ | æ•°æ®å†…å®¹ | RAG ç”¨é€” | å‘é‡åŒ–å¯¹è±¡ | æ•°æ®æ¥æº |
|--------|---------|---------|-----------|----------|
| `stock_news_embeddings` | æ–°é—»/å…¬å‘Š | æ–°é—»è¯­ä¹‰æ£€ç´¢ | `title + content_chunk` æ‹¼æ¥åå‘é‡åŒ– | akshare (Aè‚¡), yfinance (æ¸¯è‚¡/ç¾è‚¡) |
| `sql_examples_embeddings` | SQL æŸ¥è¯¢ç¤ºä¾‹ | Text-to-SQL Few-shot æ£€ç´¢ | `question` (è‡ªç„¶è¯­è¨€é—®é¢˜) å‘é‡åŒ– | äººå·¥/LLM é¢„ç”Ÿæˆ |
| `conversation_embeddings` | å¯¹è¯å†å²æ‘˜è¦ | è·¨ä¼šè¯ä¸Šä¸‹æ–‡æ£€ç´¢ | `content_summary` (å¯¹è¯æ‘˜è¦) å‘é‡åŒ– | ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ |

> [!IMPORTANT]
> æ‰€æœ‰å‘é‡è¡¨ç»Ÿä¸€ä½¿ç”¨ `VECTOR(1536)` ç»´åº¦ï¼ŒIVFFlat ç´¢å¼• + ä½™å¼¦ç›¸ä¼¼åº¦ (`vector_cosine_ops`)ã€‚

#### 3.3.1 æ–°é—»å‘é‡è¡¨ (`stock_news_embeddings`)

å­˜å‚¨æ–°é—»/å…¬å‘Šçš„åˆ†å—å‘é‡ã€‚é•¿æ–‡ç« æŒ‰ ~500 token åˆ†å—ï¼Œæ¯å—å•ç‹¬å‘é‡åŒ–ã€‚

```python
from pgvector.sqlalchemy import Vector

class StockNewsEmbedding(Base):
    """æ–°é—»/å…¬å‘Šå‘é‡åµŒå…¥è¡¨"""
    __tablename__ = "stock_news_embeddings"
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    
    # ---- å†…å®¹å­—æ®µ ----
    source_type = Column(String(20), nullable=False, comment="news / announcement")
    ticker = Column(String(20), index=True, comment="å…³è”è‚¡ç¥¨ (å¯ä¸ºç©º=å®è§‚æ–°é—»)")
    market = Column(String(5), comment="CN / HK / US")
    title = Column(Text, nullable=False, comment="æ–°é—»æ ‡é¢˜")
    content = Column(Text, nullable=False, comment="åŸæ–‡å†…å®¹ (æˆ–åˆ†å—ç‰‡æ®µ)")
    chunk_index = Column(Integer, default=0, comment="åˆ†å—ç´¢å¼• (0=ä¸åˆ†å—æˆ–ç¬¬ä¸€å—)")
    total_chunks = Column(Integer, default=1, comment="è¯¥æ–‡ç« æ€»å—æ•°")
    
    # ---- å…ƒä¿¡æ¯ ----
    summary = Column(Text, comment="LLM ç”Ÿæˆçš„æ‘˜è¦ (å¯é€‰)")
    sentiment = Column(String(10), comment="positive / negative / neutral")
    published_at = Column(DateTime(timezone=True), index=True, comment="å‘å¸ƒæ—¶é—´")
    source = Column(String(100), comment="æ•°æ®æ¥æº (eastmoney / yahoo / ...)")
    source_url = Column(Text, comment="åŸæ–‡é“¾æ¥")
    
    # ---- å‘é‡ ----
    embedding = Column(Vector(1536), comment="æ–‡æœ¬å‘é‡ (title+content æ‹¼æ¥åå‘é‡åŒ–)")
    
    # ---- æ—¶é—´æˆ³ ----
    created_at = Column(DateTime(timezone=True), default=lambda: datetime.now(timezone.utc))
    
    __table_args__ = (
        Index('idx_news_emb_ticker', 'ticker'),
        Index('idx_news_emb_published', 'published_at'),
        Index('idx_news_emb_source_type', 'source_type'),
        Index('idx_news_emb_market', 'market'),
        # pgvector å‘é‡ç´¢å¼• (IVFFlat, æ•°æ®é‡å¤§åå¯æ¢ HNSW)
        Index('idx_news_emb_vector', 'embedding',
              postgresql_using='ivfflat',
              postgresql_with={'lists': 100},
              postgresql_ops={'embedding': 'vector_cosine_ops'}),
    )
```

**å‘é‡åŒ–è§„åˆ™**ï¼š
- **å‘é‡åŒ–å¯¹è±¡**: å°† `title` å’Œ `content` æ‹¼æ¥ä¸º `"{title}\n{content}"` åä¼ ç»™ Embedding æ¨¡å‹
- **åˆ†å—ç­–ç•¥**: æŒ‰æ®µè½è¾¹ç•Œåˆ†å—ï¼Œæ¯å— ~500 tokenï¼Œç›¸é‚»å—é‡å  50 token
- **æ¯æ¡æ–°é—»å¯èƒ½äº§ç”Ÿ 1~N æ¡è®°å½•** (å–å†³äºé•¿åº¦)ï¼Œé€šè¿‡ `chunk_index` å’Œ `total_chunks` å…³è”

#### 3.3.2 SQL ç¤ºä¾‹å‘é‡è¡¨ (`sql_examples_embeddings`)

å­˜å‚¨é¢„ç”Ÿæˆçš„ã€Œè‡ªç„¶è¯­è¨€é—®é¢˜ â†” SQL æŸ¥è¯¢ã€å¯¹ã€‚Agent æ‰§è¡Œ Text-to-SQL æ—¶ï¼Œå…ˆç”¨ç”¨æˆ·é—®é¢˜å‘é‡æ£€ç´¢æœ€ç›¸ä¼¼çš„ç¤ºä¾‹ä½œä¸º Few-shot å‚è€ƒã€‚

```python
class SQLExampleEmbedding(Base):
    """SQL ç¤ºä¾‹å‘é‡åµŒå…¥è¡¨ â€” Text-to-SQL RAG Few-shot"""
    __tablename__ = "sql_examples_embeddings"
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    
    # ---- ç¤ºä¾‹å†…å®¹ ----
    question = Column(Text, nullable=False, comment="è‡ªç„¶è¯­è¨€é—®é¢˜")
    sql_query = Column(Text, nullable=False, comment="å¯¹åº”çš„ SQL æŸ¥è¯¢")
    description = Column(Text, comment="ç¤ºä¾‹è¯´æ˜/è§£é‡Š")
    
    # ---- åˆ†ç±»æ ‡ç­¾ ----
    category = Column(String(30), comment="æŸ¥è¯¢ç±»åˆ«: price/indicator/financial/news/comparison")
    tables_involved = Column(ARRAY(String), comment="æ¶‰åŠçš„è¡¨å")
    difficulty = Column(String(10), comment="easy / medium / hard")
    market = Column(String(5), comment="CN / HK / US / ALL")
    
    # ---- å‘é‡ ----
    embedding = Column(Vector(1536), comment="question çš„å‘é‡åµŒå…¥")
    
    # ---- æ—¶é—´æˆ³ ----
    created_at = Column(DateTime(timezone=True), default=lambda: datetime.now(timezone.utc))
    
    __table_args__ = (
        Index('idx_sql_exm_category', 'category'),
        Index('idx_sql_exm_difficulty', 'difficulty'),
        Index('idx_sql_exm_vector', 'embedding',
              postgresql_using='ivfflat',
              postgresql_with={'lists': 50},
              postgresql_ops={'embedding': 'vector_cosine_ops'}),
    )
```

**å‘é‡åŒ–è§„åˆ™**ï¼š
- **å‘é‡åŒ–å¯¹è±¡**: ä»…å¯¹ `question` (è‡ªç„¶è¯­è¨€é—®é¢˜) è¿›è¡Œå‘é‡åŒ–
- æŸ¥è¯¢æ—¶ç”¨ç”¨æˆ·çš„åŸå§‹é—®é¢˜å‘é‡æ£€ç´¢æœ€æ¥è¿‘çš„ç¤ºä¾‹
- éœ€è¦é¢„ç”Ÿæˆè¦†ç›–å„ç§æŸ¥è¯¢åœºæ™¯çš„ç¤ºä¾‹ (è¯¦è§ [Section 8.3](#83-sql-query-examples-é¢„ç”Ÿæˆ))

#### 3.3.3 å¯¹è¯å†å²å‘é‡è¡¨ (`conversation_embeddings`)

å­˜å‚¨å¯¹è¯æ‘˜è¦çš„å‘é‡ï¼Œç”¨äºè·¨ä¼šè¯çš„ä¸Šä¸‹æ–‡æ£€ç´¢ï¼ˆå¦‚ "æˆ‘ä¸Šæ¬¡é—®è¿‡çš„é‚£åªè‚¡ç¥¨"ï¼‰ã€‚

```python
class ConversationEmbedding(Base):
    """å¯¹è¯å†å²å‘é‡åµŒå…¥è¡¨ â€” è·¨ä¼šè¯ä¸Šä¸‹æ–‡æ£€ç´¢"""
    __tablename__ = "conversation_embeddings"
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    
    # ---- å…³è” ----
    session_id = Column(UUID(as_uuid=True), ForeignKey("chat_sessions.id"), index=True)
    message_id = Column(UUID(as_uuid=True), ForeignKey("chat_messages.id"))
    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"), index=True)
    
    # ---- å†…å®¹ ----
    content_summary = Column(Text, comment="å¯¹è¯æ‘˜è¦ (ç”± LLM ç”Ÿæˆ)")
    mentioned_tickers = Column(ARRAY(String), comment="æåˆ°çš„è‚¡ç¥¨ä»£ç ")
    intent_category = Column(String(30), comment="åŸå§‹æ„å›¾åˆ†ç±»")
    
    # ---- å‘é‡ ----
    embedding = Column(Vector(1536), comment="æ‘˜è¦çš„å‘é‡åµŒå…¥")
    
    # ---- æ—¶é—´æˆ³ ----
    created_at = Column(DateTime(timezone=True), default=lambda: datetime.now(timezone.utc))
    
    __table_args__ = (
        Index('idx_conv_emb_session', 'session_id'),
        Index('idx_conv_emb_user', 'user_id'),
        Index('idx_conv_emb_vector', 'embedding',
              postgresql_using='ivfflat',
              postgresql_with={'lists': 50},
              postgresql_ops={'embedding': 'vector_cosine_ops'}),
    )
```

**å‘é‡åŒ–è§„åˆ™**ï¼š
- **å‘é‡åŒ–å¯¹è±¡**: `content_summary` (å¯¹è¯æ‘˜è¦)
- æ¯æ¬¡å¯¹è¯ç»“æŸåï¼Œç”± LLM å¯¹æ•´è½®å¯¹è¯ç”Ÿæˆä¸€æ®µæ‘˜è¦ï¼Œå‘é‡åŒ–åå…¥åº“
- æŸ¥è¯¢æ—¶æŒ‰ `user_id` è¿‡æ»¤ + å‘é‡ç›¸ä¼¼åº¦æ’åºï¼Œæ‰¾åˆ°ç”¨æˆ·å†å²ä¸­è¯­ä¹‰æœ€ç›¸å…³çš„å¯¹è¯

#### 3.3.4 å‘é‡ç´¢å¼•ç­–ç•¥

| é˜¶æ®µ | ç´¢å¼•ç±»å‹ | é€‚ç”¨åœºæ™¯ | é…ç½® |
|------|---------|---------|------|
| **åˆæœŸ (MVP)** | IVFFlat | æ•°æ®é‡ < 10ä¸‡ | `lists = 50~100`, `probes = 10` |
| **ä¸­æœŸ** | HNSW | æ•°æ®é‡ 10ä¸‡~100ä¸‡ | `m = 16`, `ef_construction = 64` |
| **å¤§è§„æ¨¡** | HNSW + åˆ†åŒºè¡¨ | æ•°æ®é‡ > 100ä¸‡ | æŒ‰ market æˆ– published_at åˆ†åŒº |

```sql
-- MVP é˜¶æ®µæŸ¥è¯¢ç¤ºä¾‹ (IVFFlat)
SET ivfflat.probes = 10;  -- æœç´¢æ—¶æ¢æµ‹ 10 ä¸ªèšç±»

SELECT id, title, content,
       1 - (embedding <=> $1::vector) AS similarity
FROM stock_news_embeddings
WHERE ticker = '601127' AND published_at >= NOW() - INTERVAL '30 days'
ORDER BY embedding <=> $1::vector
LIMIT 10;
```

---

## 4. Agent Graph å®ç° (`agent/graph.py`)

### 4.1 LangGraph å›¾æ„å»º

```python
from langgraph.graph import StateGraph, END
from .state import AgentState
from .nodes.intent import intent_node
from .nodes.planner import planner_node
from .nodes.executor import executor_node
from .nodes.synthesizer import synthesizer_node
from .nodes.responder import responder_node


def should_decompose(state: AgentState) -> str:
    """æ¡ä»¶è·¯ç”±ï¼šæ˜¯å¦éœ€è¦é—®é¢˜æ‹†è§£"""
    if state["intent"] and state["intent"].requires_decomposition:
        return "planner"
    return "executor"


def needs_more_data(state: AgentState) -> str:
    """æ¡ä»¶è·¯ç”±ï¼šæ•°æ®æ˜¯å¦å……è¶³"""
    plan = state.get("plan")
    if plan:
        incomplete = [t for t in plan.tasks if t.status == "pending"]
        if incomplete:
            return "executor"
    return "synthesizer"


def build_agent_graph() -> StateGraph:
    """æ„å»º Agent çŠ¶æ€å›¾"""
    graph = StateGraph(AgentState)
    
    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("intent", intent_node)
    graph.add_node("planner", planner_node)
    graph.add_node("executor", executor_node)
    graph.add_node("result_check", lambda s: s)  # passthrough
    graph.add_node("synthesizer", synthesizer_node)
    graph.add_node("responder", responder_node)
    
    # å®šä¹‰è¾¹
    graph.set_entry_point("intent")
    graph.add_conditional_edges("intent", should_decompose, {
        "planner": "planner",
        "executor": "executor",
    })
    graph.add_edge("planner", "executor")
    graph.add_edge("executor", "result_check")
    graph.add_conditional_edges("result_check", needs_more_data, {
        "executor": "executor",
        "synthesizer": "synthesizer",
    })
    graph.add_edge("synthesizer", "responder")
    graph.add_edge("responder", END)
    
    return graph.compile()


# å…¨å±€ agent å®ä¾‹
agent = build_agent_graph()
```

### 4.2 æ„å›¾ç†è§£èŠ‚ç‚¹ (`nodes/intent.py`)

```python
async def intent_node(state: AgentState) -> dict:
    """æ„å›¾åˆ†ç±» + å®ä½“æå– + è‚¡ç¥¨è§£æ"""
    user_message = state["messages"][-1].content
    
    # Step 1: LLM ç»“æ„åŒ–è¾“å‡º â€” æ„å›¾åˆ†ç±»
    intent = await llm.structured_output(
        messages=[
            SystemMessage(content=INTENT_PROMPT),
            HumanMessage(content=user_message),
        ],
        schema=IntentClassification,
    )
    
    # Step 2: LLM ç»“æ„åŒ–è¾“å‡º â€” å®ä½“æå–
    entities = await llm.structured_output(
        messages=[
            SystemMessage(content=ENTITY_EXTRACTION_PROMPT),
            HumanMessage(content=user_message),
        ],
        schema=ExtractedEntities,
    )
    
    # Step 3: è‚¡ç¥¨åç§°è§£æ (æŸ¥åº“åŒ¹é…)
    resolver = StockResolver(db_session)
    resolved_stocks = []
    for stock in entities.stocks:
        resolved = await resolver.resolve(stock.raw_input or stock.name)
        if resolved:
            resolved_stocks.append(resolved)
    
    # SSE æ¨é€çŠ¶æ€
    if state.get("status_callback"):
        await state["status_callback"]({"type": "status", "status": "analyzing"})
    
    return {
        "intent": intent,
        "entities": entities,
        "resolved_stocks": resolved_stocks,
    }
```

### 4.3 æ‰§è¡Œå™¨èŠ‚ç‚¹ (`nodes/executor.py`)

```python
import asyncio
from ..state import AgentState, SubTask, TaskStatus


# å·¥å…·æ³¨å†Œè¡¨
TOOL_REGISTRY: dict[str, callable] = {
    "query_stock_price": query_stock_price_tool,
    "query_tech_indicator": query_tech_indicator_tool,
    "analyze_tech_signal": analyze_tech_signal_tool,
    "query_financial_data": query_financial_data_tool,
    "search_news": search_news_tool,
    "text_to_sql": text_to_sql_tool,
}


async def executor_node(state: AgentState) -> dict:
    """æŒ‰ DAG æ‹“æ‰‘åºæ‰§è¡Œå·¥å…·ï¼Œæ”¯æŒå±‚çº§å¹¶è¡Œ"""
    plan = state.get("plan")
    tool_results = dict(state.get("tool_results", {}))
    
    if not plan:
        # ç®€å•æŸ¥è¯¢ â€” ç›´æ¥è°ƒç”¨å•ä¸ªå·¥å…·
        tool_name = state["intent"].suggested_tools[0]
        tool_fn = TOOL_REGISTRY[tool_name]
        result = await tool_fn(state)
        tool_results["direct"] = result
        return {"tool_results": tool_results}
    
    # æŒ‰ execution_order åˆ†å±‚å¹¶è¡Œæ‰§è¡Œ
    for layer_idx, layer_task_ids in enumerate(plan.execution_order):
        if layer_idx < state.get("current_layer", 0):
            continue  # è·³è¿‡å·²å®Œæˆå±‚
        
        # æ”¶é›†æœ¬å±‚å°±ç»ªä»»åŠ¡
        ready_tasks = [
            t for t in plan.tasks
            if t.task_id in layer_task_ids and t.status == TaskStatus.PENDING
        ]
        
        # SSE æ¨é€å½“å‰æ­¥éª¤
        if state.get("status_callback"):
            await state["status_callback"]({
                "type": "status",
                "status": "retrieving",
                "steps": [{"task_id": t.task_id, "tool": t.tool_name} for t in ready_tasks],
            })
        
        # å¹¶è¡Œæ‰§è¡Œæœ¬å±‚æ‰€æœ‰ä»»åŠ¡
        async def run_task(task: SubTask):
            tool_fn = TOOL_REGISTRY.get(task.tool_name)
            if not tool_fn:
                task.status = TaskStatus.FAILED
                task.error = f"Unknown tool: {task.tool_name}"
                return
            try:
                task.status = TaskStatus.RUNNING
                result = await asyncio.wait_for(
                    tool_fn(state, **task.tool_params),
                    timeout=get_settings().TOOL_TIMEOUT_SECONDS,
                )
                task.status = TaskStatus.COMPLETED
                task.result = result
                tool_results[task.task_id] = result
            except asyncio.TimeoutError:
                task.status = TaskStatus.FAILED
                task.error = "Tool execution timeout"
            except Exception as e:
                task.status = TaskStatus.FAILED
                task.error = str(e)
        
        await asyncio.gather(*[run_task(t) for t in ready_tasks])
    
    return {
        "tool_results": tool_results,
        "current_layer": len(plan.execution_order),
        "plan": plan,
    }
```

---

## 5. å·¥å…·å®ç° (`tools/`)

### 5.1 è‚¡ç¥¨ä»·æ ¼æŸ¥è¯¢ (`tools/stock_price.py`)

```python
from pydantic import BaseModel, Field


class StockPriceParams(BaseModel):
    ticker: str
    days: int = Field(default=30, ge=1, le=365)
    market: str = "CN"


class StockPriceResult(BaseModel):
    ticker: str
    market: str
    records: list[dict]   # [{trade_date, open, close, high, low, volume}, ...]
    latest_close: float | None
    period: str


async def query_stock_price_tool(state: AgentState, **kwargs) -> StockPriceResult:
    """æŸ¥è¯¢è‚¡ç¥¨ä»·æ ¼æ•°æ®"""
    params = StockPriceParams(**kwargs) if kwargs else _extract_params(state)
    
    query = (
        select(StockDailyPrice)
        .where(StockDailyPrice.ticker == params.ticker)
        .order_by(StockDailyPrice.trade_date.desc())
        .limit(params.days)
    )
    
    async with db_session() as session:
        results = await session.execute(query)
        records = results.scalars().all()
    
    return StockPriceResult(
        ticker=params.ticker,
        market=params.market,
        records=[row_to_dict(r) for r in reversed(records)],
        latest_close=records[0].close if records else None,
        period=f"æœ€è¿‘{params.days}æ—¥",
    )
```

### 5.2 æ–°é—» RAG æ£€ç´¢ (`tools/news_search.py`)

```python
class NewsSearchParams(BaseModel):
    query: str             # è‡ªç„¶è¯­è¨€æŸ¥è¯¢
    ticker: str | None     # å¯é€‰ ticker è¿‡æ»¤
    top_k: int = 10
    days: int | None = 30  # æ—¶é—´èŒƒå›´


class NewsSearchResult(BaseModel):
    articles: list[dict]   # [{title, content, source, published_at, similarity}, ...]
    total_found: int


async def search_news_tool(state: AgentState, **kwargs) -> NewsSearchResult:
    """æ–°é—»è¯­ä¹‰æ£€ç´¢ â€” RAG"""
    params = NewsSearchParams(**kwargs) if kwargs else _extract_params(state)
    
    # Step 1: å‘é‡åŒ–æŸ¥è¯¢
    embedding_service = get_embedding_service()
    query_vector = await embedding_service.embed_query(params.query)
    
    # Step 2: pgvector ç›¸ä¼¼åº¦æ£€ç´¢ + è¿‡æ»¤
    rag_service = get_rag_service()
    results = await rag_service.search_news(
        query_vector=query_vector,
        ticker=params.ticker,
        top_k=params.top_k,
        days=params.days,
    )
    
    return NewsSearchResult(
        articles=[
            {
                "title": r.title,
                "content": r.content[:500],   # æˆªæ–­è¿‡é•¿å†…å®¹
                "source": r.source,
                "published_at": r.published_at.isoformat(),
                "similarity": round(r.similarity, 4),
            }
            for r in results
        ],
        total_found=len(results),
    )
```

### 5.3 Text-to-SQL (`tools/text_to_sql.py`)

```python
class TextToSQLResult(BaseModel):
    generated_sql: str
    query_result: list[dict]
    row_count: int
    explanation: str


async def text_to_sql_tool(state: AgentState, **kwargs) -> TextToSQLResult:
    """è‡ªç„¶è¯­è¨€ â†’ SQL æŸ¥è¯¢"""
    question = kwargs.get("question", state["messages"][-1].content)
    
    # Step 1: RAG æ£€ç´¢ç›¸ä¼¼ SQL ç¤ºä¾‹
    embedding_svc = get_embedding_service()
    q_vector = await embedding_svc.embed_query(question)
    similar_examples = await rag_service.search_sql_examples(q_vector, top_k=3)
    
    # Step 2: æ„å»º prompt (Schema + Few-shot Examples)
    prompt = TEXT_TO_SQL_PROMPT.format(
        schema=get_table_schemas(),
        examples=format_sql_examples(similar_examples),
        question=question,
    )
    
    # Step 3: LLM ç”Ÿæˆ SQL
    generated_sql = await llm.chat([
        SystemMessage(content=prompt),
        HumanMessage(content=question),
    ])
    
    # Step 4: å®‰å…¨æ ¡éªŒ (ä»…å…è®¸ SELECT)
    if not validate_sql_safety(generated_sql):
        raise ValueError("Generated SQL contains unsafe operations")
    
    # Step 5: æ‰§è¡ŒæŸ¥è¯¢
    async with db_session() as session:
        result = await session.execute(text(generated_sql))
        rows = result.fetchmany(get_settings().SQL_MAX_ROWS)
    
    return TextToSQLResult(
        generated_sql=generated_sql,
        query_result=[dict(r._mapping) for r in rows],
        row_count=len(rows),
        explanation=f"åŸºäº SQL æŸ¥è¯¢è·å–äº† {len(rows)} æ¡è®°å½•",
    )


def validate_sql_safety(sql: str) -> bool:
    """SQL å®‰å…¨æ ¡éªŒ â€” ä»…å…è®¸ SELECT"""
    sql_upper = sql.strip().upper()
    forbidden = ["INSERT", "UPDATE", "DELETE", "DROP", "ALTER", "TRUNCATE", "CREATE"]
    return sql_upper.startswith("SELECT") and not any(kw in sql_upper for kw in forbidden)
```

### 5.4 è‚¡ç¥¨åç§°è§£æ (`tools/stock_resolver.py`)

```python
class StockResolver:
    """åŸºäº stock_basic_info çš„æ¨¡ç³Šè‚¡ç¥¨åç§°è§£æ"""
    
    def __init__(self, db_session):
        self.db = db_session
    
    async def resolve(self, query: str) -> StockEntity | None:
        """å¤šç­–ç•¥åŒ¹é…ï¼šç²¾ç¡® â†’ æ¨¡ç³Š â†’ å‘é‡"""
        
        # 1. ç²¾ç¡®åŒ¹é… ticker
        result = await self._exact_ticker_match(query)
        if result:
            return result
        
        # 2. ç²¾ç¡®åŒ¹é… stock_name
        result = await self._exact_name_match(query)
        if result:
            return result
        
        # 3. LIKE æ¨¡ç³ŠåŒ¹é…
        result = await self._fuzzy_match(query)
        if result:
            return result
        
        # 4. (å¯é€‰) å‘é‡ç›¸ä¼¼åº¦åŒ¹é…
        return None
    
    async def _exact_ticker_match(self, query: str) -> StockEntity | None:
        """ç²¾ç¡® ticker åŒ¹é… (600519 / 01024.HK / GOOG)"""
        stmt = select(StockBasicInfo).where(StockBasicInfo.ticker == query)
        result = await self.db.execute(stmt)
        row = result.scalar_one_or_none()
        if row:
            return StockEntity(
                name=row.stock_name,
                ticker=row.ticker,
                market=self._detect_market(row.ticker),
                raw_input=query,
            )
        return None
    
    async def _fuzzy_match(self, query: str) -> StockEntity | None:
        """æ¨¡ç³ŠåŒ¹é… (LIKE %query%)"""
        stmt = (
            select(StockBasicInfo)
            .where(StockBasicInfo.stock_name.ilike(f"%{query}%"))
            .limit(5)
        )
        result = await self.db.execute(stmt)
        rows = result.scalars().all()
        if len(rows) == 1:
            return self._to_entity(rows[0], query)
        elif len(rows) > 1:
            # å¤šä¸ªå€™é€‰ â€” æŒ‰åç§°é•¿åº¦æ’åºå–æœ€çŸ­ (æœ€ç²¾ç¡®)
            best = min(rows, key=lambda r: len(r.stock_name))
            return self._to_entity(best, query)
        return None
    
    @staticmethod
    def _detect_market(ticker: str) -> MarketType:
        if ticker.endswith(".HK"):
            return MarketType.HK
        elif ticker.isdigit() and len(ticker) == 6:
            return MarketType.CN
        else:
            return MarketType.US
```

---

## 6. æœåŠ¡å±‚ (`services/`)

### 6.1 Embedding æœåŠ¡ (`services/embedding.py`)

```python
from abc import ABC, abstractmethod


class EmbeddingProvider(ABC):
    """Embedding æŠ½è±¡æ¥å£"""
    
    @abstractmethod
    async def embed(self, texts: list[str]) -> list[list[float]]:
        """æ‰¹é‡æ–‡æœ¬å‘é‡åŒ–"""
        ...
    
    async def embed_query(self, text: str) -> list[float]:
        """å•æ¡æ–‡æœ¬å‘é‡åŒ–"""
        results = await self.embed([text])
        return results[0]


class OpenAIEmbedding(EmbeddingProvider):
    def __init__(self, api_key: str, model: str, dimensions: int, base_url: str | None = None):
        from openai import AsyncOpenAI
        self.client = AsyncOpenAI(api_key=api_key, base_url=base_url)
        self.model = model
        self.dimensions = dimensions
    
    async def embed(self, texts: list[str]) -> list[list[float]]:
        response = await self.client.embeddings.create(
            model=self.model,
            input=texts,
            dimensions=self.dimensions,     # OpenAI åŸç”Ÿå‚æ•°
        )
        return [item.embedding for item in response.data]


class GeminiEmbedding(EmbeddingProvider):
    def __init__(self, api_key: str, model: str, dimensions: int):
        import google.generativeai as genai
        genai.configure(api_key=api_key)
        self.model = model
        self.dimensions = dimensions
    
    async def embed(self, texts: list[str]) -> list[list[float]]:
        import google.generativeai as genai
        result = genai.embed_content(
            model=self.model,
            content=texts,
            task_type="retrieval_document",
            output_dimensionality=self.dimensions,  # Gemini æˆªæ–­å‚æ•°
        )
        return result["embedding"] if isinstance(result["embedding"][0], list) else [result["embedding"]]


class ZhipuEmbedding(EmbeddingProvider):
    def __init__(self, api_key: str, model: str, dimensions: int):
        from zhipuai import ZhipuAI
        self.client = ZhipuAI(api_key=api_key)
        self.model = model
        self.dimensions = dimensions
    
    async def embed(self, texts: list[str]) -> list[list[float]]:
        results = []
        for text in texts:  # Zhipu ä¸æ”¯æŒæ‰¹é‡
            response = self.client.embeddings.create(
                model=self.model,
                input=text,
                dimensions=self.dimensions,
            )
            results.append(response.data[0].embedding)
        return results


# ---- å·¥å‚å‡½æ•° ----

def create_embedding_provider(settings: Settings) -> EmbeddingProvider:
    match settings.EMBEDDING_PROVIDER:
        case "openai":
            return OpenAIEmbedding(
                api_key=settings.EMBEDDING_API_KEY,
                model=settings.EMBEDDING_MODEL,
                dimensions=settings.EMBEDDING_DIMENSIONS,
                base_url=settings.EMBEDDING_BASE_URL,
            )
        case "gemini":
            return GeminiEmbedding(
                api_key=settings.EMBEDDING_API_KEY,
                model=settings.EMBEDDING_MODEL,
                dimensions=settings.EMBEDDING_DIMENSIONS,
            )
        case "zhipu":
            return ZhipuEmbedding(
                api_key=settings.EMBEDDING_API_KEY,
                model=settings.EMBEDDING_MODEL,
                dimensions=settings.EMBEDDING_DIMENSIONS,
            )
        case _:
            raise ValueError(f"Unsupported embedding provider: {settings.EMBEDDING_PROVIDER}")
```

### 6.2 RAG æ£€ç´¢æœåŠ¡ (`services/rag.py`)

```python
from sqlalchemy import text as sql_text


class RAGService:
    """å‘é‡æ£€ç´¢æœåŠ¡ â€” å°è£… pgvector æŸ¥è¯¢"""
    
    def __init__(self, db_session_factory, embedding_provider: EmbeddingProvider):
        self.db_factory = db_session_factory
        self.embedder = embedding_provider
    
    async def search_news(
        self,
        query_vector: list[float],
        ticker: str | None = None,
        top_k: int = 10,
        days: int | None = 30,
    ) -> list[dict]:
        """æ–°é—»å‘é‡æ£€ç´¢"""
        filters = []
        params = {"query_vec": str(query_vector), "top_k": top_k}
        
        if ticker:
            filters.append("ticker = :ticker")
            params["ticker"] = ticker
        if days:
            filters.append("published_at >= NOW() - INTERVAL ':days days'")
            params["days"] = days
        
        where_clause = " AND ".join(filters) if filters else "TRUE"
        
        query = f"""
            SELECT id, ticker, title, content, source, published_at,
                   1 - (embedding <=> :query_vec::vector) AS similarity
            FROM stock_news_embeddings
            WHERE {where_clause}
            ORDER BY embedding <=> :query_vec::vector
            LIMIT :top_k
        """
        
        async with self.db_factory() as session:
            result = await session.execute(sql_text(query), params)
            return [dict(row._mapping) for row in result.fetchall()]
    
    async def search_sql_examples(
        self,
        query_vector: list[float],
        top_k: int = 3,
    ) -> list[dict]:
        """SQL ç¤ºä¾‹å‘é‡æ£€ç´¢ (ç”¨äº Text-to-SQL Few-shot)"""
        query = """
            SELECT question, sql_query, description, tables_involved,
                   1 - (embedding <=> :query_vec::vector) AS similarity
            FROM sql_examples_embeddings
            ORDER BY embedding <=> :query_vec::vector
            LIMIT :top_k
        """
        async with self.db_factory() as session:
            result = await session.execute(
                sql_text(query),
                {"query_vec": str(query_vector), "top_k": top_k},
            )
            return [dict(row._mapping) for row in result.fetchall()]
```

---

## 7. API å±‚ (`api/`)

### 7.1 èŠå¤© API â€” SSE æµå¼æ¨é€ (`api/chat.py`)

```python
import json
import asyncio
from fastapi import APIRouter, Depends
from fastapi.responses import StreamingResponse
from pydantic import BaseModel


router = APIRouter(prefix="/api")


class ChatRequest(BaseModel):
    message: str
    session_id: str | None = None


@router.post("/chat")
async def chat(request: ChatRequest):
    """å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼Œè¿”å› SSE æµ"""
    
    async def event_stream():
        queue: asyncio.Queue = asyncio.Queue()
        
        async def status_callback(event: dict):
            """Agent å†…éƒ¨è°ƒç”¨æ­¤å›è°ƒæ¨é€çŠ¶æ€"""
            await queue.put(event)
        
        # åˆå§‹åŒ– Agent çŠ¶æ€
        initial_state: AgentState = {
            "session_id": request.session_id or str(uuid.uuid4()),
            "user_id": "default",
            "messages": [HumanMessage(content=request.message)],
            "intent": None,
            "entities": None,
            "resolved_stocks": [],
            "plan": None,
            "current_layer": 0,
            "tool_results": {},
            "status_callback": status_callback,
            "analysis_result": "",
            "data_sources": [],
            "risk_disclaimer": "",
        }
        
        # å¼‚æ­¥å¯åŠ¨ Agent æ‰§è¡Œ
        agent_task = asyncio.create_task(agent.ainvoke(initial_state))
        
        # æŒç»­ä»é˜Ÿåˆ—è¯»å–äº‹ä»¶å¹¶æ¨é€
        while not agent_task.done():
            try:
                event = await asyncio.wait_for(queue.get(), timeout=0.5)
                yield f"data: {json.dumps(event, ensure_ascii=False)}\n\n"
            except asyncio.TimeoutError:
                continue
        
        # Agent æ‰§è¡Œå®Œæ¯•ï¼Œæ¨é€æœ€ç»ˆç»“æœ
        final_state = agent_task.result()
        yield f"data: {json.dumps({'type': 'result', 'content': final_state['analysis_result'], 'sources': final_state['data_sources'], 'disclaimer': final_state['risk_disclaimer']}, ensure_ascii=False)}\n\n"
        yield "data: [DONE]\n\n"
    
    return StreamingResponse(
        event_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",   # Nginx SSE å…¼å®¹
        },
    )
```

### 7.2 ä¼šè¯ç®¡ç† API (`api/session.py`)

```python
router = APIRouter(prefix="/api/sessions")


@router.get("/")
async def list_sessions(user_id: str = "default"):
    """è·å–ç”¨æˆ·ä¼šè¯åˆ—è¡¨"""
    async with db_session() as session:
        stmt = (
            select(ChatSession)
            .where(ChatSession.user_id == user_id, ChatSession.status == "active")
            .order_by(ChatSession.updated_at.desc())
        )
        result = await session.execute(stmt)
        return [session_to_dict(s) for s in result.scalars().all()]


@router.get("/{session_id}")
async def get_session(session_id: str):
    """è·å–ä¼šè¯è¯¦æƒ… + æ¶ˆæ¯å†å²"""
    async with db_session() as session:
        chat_session = await session.get(ChatSession, session_id)
        messages = await session.execute(
            select(ChatMessage)
            .where(ChatMessage.session_id == session_id)
            .order_by(ChatMessage.created_at)
        )
        return {
            "session": session_to_dict(chat_session),
            "messages": [msg_to_dict(m) for m in messages.scalars().all()],
        }


@router.delete("/{session_id}", status_code=204)
async def archive_session(session_id: str):
    """å½’æ¡£ä¼šè¯"""
    async with db_session() as session:
        chat_session = await session.get(ChatSession, session_id)
        chat_session.status = "archived"
        await session.commit()
```

---

## 8. æ•°æ®ç®¡é“ (`data_pipeline/`)

### 8.1 æ‰§è¡Œæµç¨‹

> [!NOTE]
> **MVP é˜¶æ®µ**ï¼šæ‰€æœ‰æ•°æ®è·å–å‡ä¸ºæ‰‹åŠ¨è„šæœ¬æ‰§è¡Œ (å‚è§ [Section 1.2](#12-mvp-å¼€å‘èŒƒå›´))ï¼Œä¸è®¾ç½®å®šæ—¶ä»»åŠ¡ã€‚åæœŸå†å¼•å…¥è°ƒåº¦æ¡†æ¶ã€‚

```mermaid
flowchart TD
    MANUAL["ğŸ‘¨â€ğŸ’» æ‰‹åŠ¨æ‰§è¡Œè„šæœ¬"] --> FETCH["Step 1: æ•°æ®è·å–"]
    FETCH --> CALC["Step 2: æŒ‡æ ‡è®¡ç®—"]
    CALC --> NEWS["Step 3: æ–°é—»è·å–"]
    NEWS --> EMB["Step 4: æ–°é—»å‘é‡åŒ–"]
    EMB --> SQL_SEED["Step 5: SQL ç¤ºä¾‹å…¥åº“"]
    
    subgraph FETCH_DETAIL["æ•°æ®è·å–"]
        AK["akshare_fetcher.py<br/>Aè‚¡: 601127, 688981"]
        YF["yfinance_fetcher.py<br/>æ¸¯è‚¡: 9988.HK, 0700.HK, 1024.HK<br/>ç¾è‚¡: AAPL, MSFT, NVDA, GOOG, AMZN, META, TSLA"]
    end
    
    subgraph CALC_DETAIL["æŒ‡æ ‡è®¡ç®—"]
        IND["indicator_calculator.py<br/>6 ç±»æŠ€æœ¯æŒ‡æ ‡<br/>åŸºäº pandas + ta"]
    end
    
    subgraph NEWS_DETAIL["æ–°é—»è·å–"]
        NF["news_fetcher.py<br/>akshare (Aè‚¡) + yfinance (æ¸¯è‚¡/ç¾è‚¡)"]
    end
    
    subgraph EMB_DETAIL["å‘é‡åŒ–å…¥åº“"]
        EP["embedding_pipeline.py<br/>æ–°é—»åˆ†å— â†’ Embedding â†’ INSERT"]
    end
    
    subgraph SQL_DETAIL["SQL ç¤ºä¾‹å…¥åº“"]
        SS["sql_examples_seeder.py<br/>é¢„ç”Ÿæˆ SQL ç¤ºä¾‹ â†’ Embedding â†’ INSERT"]
    end
    
    FETCH --> FETCH_DETAIL
    CALC --> CALC_DETAIL
    NEWS --> NEWS_DETAIL
    EMB --> EMB_DETAIL
    SQL_SEED --> SQL_DETAIL
```

### 8.2 æ–°é—»å‘é‡åŒ–ç®¡é“ (`data_pipeline/embedding_pipeline.py`)

```python
async def process_news_batch(news_items: list[dict], embedding_provider: EmbeddingProvider):
    """æ–°é—»æ–‡ç«  â†’ åˆ†å— â†’ å‘é‡åŒ– â†’ å…¥åº“"""
    
    for item in news_items:
        # Step 1: é•¿æ–‡åˆ†å— (~500 token)
        chunks = chunk_text(item["content"], max_tokens=500, overlap_tokens=50)
        
        # Step 2: æ‰¹é‡å‘é‡åŒ– (title + chunk æ‹¼æ¥)
        texts = [f"{item['title']}\n{chunk}" for chunk in chunks]
        vectors = await embedding_provider.embed(texts)
        
        # Step 3: å†™å…¥ pgvector è¡¨
        for i, (chunk, vector) in enumerate(zip(chunks, vectors)):
            await insert_news_embedding(
                ticker=item.get("ticker"),
                title=item["title"],
                content=chunk,
                chunk_index=i,
                total_chunks=len(chunks),
                published_at=item["published_at"],
                source=item["source"],
                embedding=vector,
            )


def chunk_text(text: str, max_tokens: int = 500, overlap_tokens: int = 50) -> list[str]:
    """æŒ‰æ®µè½/å¥å­è¾¹ç•Œåˆ†å—"""
    paragraphs = text.split("\n\n")
    chunks, current_chunk = [], ""
    
    for para in paragraphs:
        if estimate_tokens(current_chunk + para) > max_tokens:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = para
        else:
            current_chunk += "\n\n" + para
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks if chunks else [text]
```

### 8.3 SQL Query Examples é¢„ç”Ÿæˆ

Text-to-SQL çš„ **RAG å¢å¼º Few-shot** æ˜¯ç³»ç»Ÿæ ¸å¿ƒèƒ½åŠ›ä¹‹ä¸€ã€‚Agent åœ¨ç”Ÿæˆ SQL å‰ï¼Œå…ˆç”¨ç”¨æˆ·é—®é¢˜å‘é‡æ£€ç´¢ `sql_examples_embeddings` è¡¨ä¸­æœ€ç›¸ä¼¼çš„ç¤ºä¾‹ä½œä¸ºå‚è€ƒã€‚è¿™äº›ç¤ºä¾‹éœ€è¦ **é¢„å…ˆæ‰¹é‡ç”Ÿæˆå¹¶å‘é‡åŒ–å…¥åº“**ã€‚

#### 8.3.1 è®¾è®¡æ€è·¯

```mermaid
flowchart LR
    subgraph Generate["Step 1: ç”Ÿæˆç¤ºä¾‹"]
        MANUAL_WRITE["äººå·¥ç¼–å†™<br/>æ ¸å¿ƒ/æ˜“é”™ç¤ºä¾‹"]
        LLM_GEN["LLM æ‰¹é‡ç”Ÿæˆ<br/>æ‰©å……è¦†ç›–é¢"]
    end
    
    subgraph Process["Step 2: å‘é‡åŒ–å…¥åº“"]
        EMB_Q["å¯¹æ¯ä¸ª question<br/>è°ƒç”¨ Embedding"]
        INSERT["INSERT INTO<br/>sql_examples_embeddings"]
    end
    
    subgraph Runtime["Step 3: è¿è¡Œæ—¶æ£€ç´¢"]
        USER_Q["ç”¨æˆ·é—®é¢˜"] --> EMB_UQ["å‘é‡åŒ–"]
        EMB_UQ --> SEARCH["pgvector ç›¸ä¼¼åº¦æ£€ç´¢<br/>Top-3 ç¤ºä¾‹"]
        SEARCH --> PROMPT["æ³¨å…¥ LLM Prompt<br/>ä½œä¸º Few-shot"]
    end
    
    MANUAL_WRITE & LLM_GEN --> EMB_Q --> INSERT
```

#### 8.3.2 ç¤ºä¾‹æ•°æ®æ ¼å¼

æ¯æ¡ SQL ç¤ºä¾‹åŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š

```python
class SQLExample(BaseModel):
    """ä¸€æ¡ SQL æŸ¥è¯¢ç¤ºä¾‹"""
    question: str          # è‡ªç„¶è¯­è¨€é—®é¢˜ (ä¸­æ–‡)
    sql_query: str         # å¯¹åº”çš„ SQL æŸ¥è¯¢
    description: str       # ç¤ºä¾‹è¯´æ˜
    category: str          # price | indicator | financial | news | comparison | meta
    tables_involved: list[str]  # æ¶‰åŠçš„è¡¨å
    difficulty: str        # easy | medium | hard
    market: str            # CN | HK | US | ALL
```

#### 8.3.3 é¢„ç”Ÿæˆç¤ºä¾‹æ¸…å•

æŒ‰ **æŸ¥è¯¢ç±»åˆ«** å’Œ **æ¶‰åŠè¡¨** ç³»ç»Ÿæ€§è¦†ç›–ï¼ŒåˆæœŸç›®æ ‡ **50-80 æ¡** ç²¾é€‰ç¤ºä¾‹ã€‚ä»¥ä¸‹æ˜¯å„ç±»åˆ«çš„ä»£è¡¨æ€§ç¤ºä¾‹ï¼š

##### ğŸ“Š ä»·æ ¼æŸ¥è¯¢ (category: `price`)

```python
SQL_EXAMPLES_PRICE = [
    {
        "question": "èŒ…å°æœ€è¿‘30å¤©çš„æ”¶ç›˜ä»·",
        "sql_query": """SELECT ticker, trade_date, close
FROM stock_daily_price
WHERE ticker = '600519'
ORDER BY trade_date DESC
LIMIT 30;""",
        "category": "price",
        "tables_involved": ["stock_daily_price"],
        "difficulty": "easy",
        "market": "CN",
    },
    {
        "question": "NVIDIAä»Šå¹´ä»¥æ¥çš„æœ€é«˜ä»·å’Œæœ€ä½ä»·",
        "sql_query": """SELECT ticker, MAX(high) AS year_high, MIN(low) AS year_low,
       MAX(high) - MIN(low) AS price_range
FROM stock_daily_price
WHERE ticker = 'NVDA'
  AND trade_date >= DATE_TRUNC('year', CURRENT_DATE)
GROUP BY ticker;""",
        "category": "price",
        "tables_involved": ["stock_daily_price"],
        "difficulty": "easy",
        "market": "US",
    },
    {
        "question": "å¯¹æ¯”è…¾è®¯å’Œé˜¿é‡Œæœ€è¿‘ä¸€å‘¨çš„æ—¥æˆäº¤é‡",
        "sql_query": """SELECT ticker, trade_date, volume
FROM stock_daily_price
WHERE ticker IN ('0700.HK', '9988.HK')
  AND trade_date >= CURRENT_DATE - INTERVAL '7 days'
ORDER BY trade_date, ticker;""",
        "category": "price",
        "tables_involved": ["stock_daily_price"],
        "difficulty": "easy",
        "market": "HK",
    },
    {
        "question": "èµ›åŠ›æ–¯æœ€è¿‘5ä¸ªäº¤æ˜“æ—¥æ¶¨è·Œå¹…",
        "sql_query": """SELECT ticker, trade_date, close, pct_chg
FROM stock_daily_price
WHERE ticker = '601127'
ORDER BY trade_date DESC
LIMIT 5;""",
        "category": "price",
        "tables_involved": ["stock_daily_price"],
        "difficulty": "easy",
        "market": "CN",
    },
    {
        "question": "è‹¹æœè¿‡å»ä¸‰ä¸ªæœˆå¹³å‡æ”¶ç›˜ä»·",
        "sql_query": """SELECT ticker, AVG(close) AS avg_close, COUNT(*) AS trading_days
FROM stock_daily_price
WHERE ticker = 'AAPL'
  AND trade_date >= CURRENT_DATE - INTERVAL '3 months'
GROUP BY ticker;""",
        "category": "price",
        "tables_involved": ["stock_daily_price"],
        "difficulty": "easy",
        "market": "US",
    },
]
```

##### ğŸ“ˆ æŠ€æœ¯æŒ‡æ ‡æŸ¥è¯¢ (category: `indicator`)

```python
SQL_EXAMPLES_INDICATOR = [
    {
        "question": "ä¸­èŠ¯å›½é™…æœ€è¿‘çš„MACDæŒ‡æ ‡",
        "sql_query": """SELECT ticker, trade_date, macd_diff, macd_dea, macd_hist
FROM stock_technical_indicators
WHERE ticker = '688981'
ORDER BY trade_date DESC
LIMIT 20;""",
        "description": "åŸºç¡€å•æŒ‡æ ‡æŸ¥è¯¢ï¼Œå±•ç¤º MACD ä¸‰ä¸ªåˆ†é‡çš„æ­£ç¡®å­—æ®µå",
        "category": "indicator",
        "tables_involved": ["stock_technical_indicators"],
        "difficulty": "easy",
        "market": "CN",
    },
    {
        "question": "å¿«æ‰‹RSIæ˜¯å¦è¶…ä¹°",
        "sql_query": """SELECT ticker, trade_date, rsi_6, rsi_12, rsi_24,
       CASE WHEN rsi_6 > 80 THEN 'è¶…ä¹°'
            WHEN rsi_6 < 20 THEN 'è¶…å–'
            ELSE 'æ­£å¸¸' END AS rsi_status
FROM stock_technical_indicators
WHERE ticker = '1024.HK'
ORDER BY trade_date DESC
LIMIT 1;""",
        "description": "CASE WHEN æ¡ä»¶åˆ¤æ–­ï¼Œå±•ç¤º RSI è¶…ä¹°è¶…å–é˜ˆå€¼åˆ¤å®š",
        "category": "indicator",
        "tables_involved": ["stock_technical_indicators"],
        "difficulty": "medium",
        "market": "HK",
    },
    {
        "question": "Teslaå¸ƒæ—å¸¦æ”¶çª„äº†å—",
        "sql_query": """SELECT ticker, trade_date,
       boll_upper, boll_middle, boll_lower,
       boll_upper - boll_lower AS boll_width
FROM stock_technical_indicators
WHERE ticker = 'TSLA'
ORDER BY trade_date DESC
LIMIT 20;""",
        "description": "è®¡ç®—æ´¾ç”Ÿå­—æ®µ (å¸ƒæ—å¸¦å®½åº¦)ï¼Œå±•ç¤ºåˆ—å boll_upper/middle/lower",
        "category": "indicator",
        "tables_involved": ["stock_technical_indicators"],
        "difficulty": "medium",
        "market": "US",
    },
]
```

##### ğŸ¯ ç­–ç•¥ä¿¡å·æŸ¥è¯¢ (category: `signal`)

```python
SQL_EXAMPLES_SIGNAL = [
    {
        "question": "NVIDIAç›®å‰æœ‰æ²¡æœ‰è¶‹åŠ¿è·Ÿè¸ªçš„ä¹°å…¥ä¿¡å·",
        "sql_query": """SELECT ticker, trade_date,
       trend_signal, trend_strength, trend_confidence,
       adx, plus_di, minus_di
FROM stock_technical_trend_signal_indicators
WHERE ticker = 'NVDA'
ORDER BY trade_date DESC
LIMIT 5;""",
        "description": "è¶‹åŠ¿ä¿¡å·è¡¨æŸ¥è¯¢ï¼ŒåŒ…å« ADX å’Œ DI æ–¹å‘æŒ‡æ ‡çš„å®Œæ•´å­—æ®µ",
        "category": "signal",
        "tables_involved": ["stock_technical_trend_signal_indicators"],
        "difficulty": "medium",
        "market": "US",
    },
    {
        "question": "èµ›åŠ›æ–¯åŠ¨é‡ç­–ç•¥ç»™å‡ºä»€ä¹ˆä¿¡å·",
        "sql_query": """SELECT ticker, trade_date,
       momentum_signal, momentum_score, momentum_confidence,
       mom_1m, mom_3m, volume_momentum
FROM stock_technical_momentum_signal_indicators
WHERE ticker = '601127'
ORDER BY trade_date DESC
LIMIT 5;""",
        "description": "åŠ¨é‡ç­–ç•¥ä¿¡å·æŸ¥è¯¢ï¼Œå±•ç¤ºå¤šå‘¨æœŸåŠ¨é‡å’Œæˆäº¤é‡ç¡®è®¤æŒ‡æ ‡",
        "category": "signal",
        "tables_involved": ["stock_technical_momentum_signal_indicators"],
        "difficulty": "medium",
        "market": "CN",
    },
    {
        "question": "è…¾è®¯çš„æ³¢åŠ¨ç‡ç­–ç•¥æŒ‡æ ‡",
        "sql_query": """SELECT ticker, trade_date,
       volatility_signal, volatility_confidence,
       hist_vol_21, atr_14, vol_z_score
FROM stock_technical_volatility_signal_indicators
WHERE ticker = '0700.HK'
ORDER BY trade_date DESC
LIMIT 10;""",
        "description": "æ³¢åŠ¨ç‡ç­–ç•¥ä¿¡å·æŸ¥è¯¢ï¼Œå±•ç¤ºæ­£ç¡®çš„å­—æ®µå hist_vol_21/vol_z_score",
        "category": "signal",
        "tables_involved": ["stock_technical_volatility_signal_indicators"],
        "difficulty": "medium",
        "market": "HK",
    },
]
```

##### ğŸ’° è´¢åŠ¡æ•°æ®æŸ¥è¯¢ (category: `financial`)

```python
SQL_EXAMPLES_FINANCIAL = [
    {
        "question": "é˜¿é‡Œå·´å·´æœ€æ–°ä¸€å­£çš„è¥æ”¶å’Œå‡€åˆ©æ¶¦",
        "sql_query": """SELECT ticker, report_period, period,
       gross_margin, operating_margin, net_margin
FROM financial_metrics
WHERE ticker = '9988.HK'
ORDER BY report_period DESC
LIMIT 1;""",
        "description": "æœ€æ–°ä¸€æœŸè´¢æŠ¥æŸ¥è¯¢ (ORDER BY + LIMIT 1 æ¨¡å¼)",
        "category": "financial",
        "tables_involved": ["financial_metrics"],
        "difficulty": "easy",
        "market": "HK",
    },
    {
        "question": "Googleè¿‘ä¸¤å¹´çš„PEå˜åŒ–è¶‹åŠ¿",
        "sql_query": """SELECT ticker, report_period, price_to_earnings_ratio
FROM financial_metrics
WHERE ticker = 'GOOG'
  AND report_period >= '2023-01-01'
ORDER BY report_period;""",
        "description": "PE å­—æ®µåæ˜¯ price_to_earnings_ratio (ä¸æ˜¯ pe_ratio)ï¼Œæ—¥æœŸç”¨å­—ç¬¦ä¸²æ¯”è¾ƒ",
        "category": "financial",
        "tables_involved": ["financial_metrics"],
        "difficulty": "easy",
        "market": "US",
    },
    {
        "question": "å¯¹æ¯”è‹¹æœå’Œå¾®è½¯çš„ROE",
        "sql_query": """SELECT ticker, report_period, return_on_equity
FROM financial_metrics
WHERE ticker IN ('AAPL', 'MSFT')
ORDER BY report_period DESC, ticker
LIMIT 10;""",
        "description": "ROE å­—æ®µåæ˜¯ return_on_equity (ä¸æ˜¯ roe)ï¼Œå¤šè‚¡å¯¹æ¯”ç”¨ IN å­å¥",
        "category": "financial",
        "tables_involved": ["financial_metrics"],
        "difficulty": "medium",
        "market": "US",
    },
]
```

##### ğŸ·ï¸ å…ƒæ•°æ®/åŸºæœ¬ä¿¡æ¯æŸ¥è¯¢ (category: `meta`)

```python
SQL_EXAMPLES_META = [
    {
        "question": "å¿«æ‰‹çš„ä¸Šå¸‚æ—¶é—´å’Œæ‰€å±è¡Œä¸š",
        "sql_query": """SELECT ticker, stock_name, market, industry, list_date
FROM stock_basic_info
WHERE ticker = '1024.HK';""",
        "category": "meta",
        "tables_involved": ["stock_basic_info"],
        "difficulty": "easy",
        "market": "HK",
    },
    {
        "question": "Aè‚¡æœ‰å“ªäº›åŠå¯¼ä½“è¡Œä¸šçš„è‚¡ç¥¨",
        "sql_query": """SELECT ticker, stock_name, industry
FROM stock_basic_info
WHERE market = 'CN' AND industry ILIKE '%åŠå¯¼ä½“%'
ORDER BY stock_name;""",
        "category": "meta",
        "tables_involved": ["stock_basic_info"],
        "difficulty": "easy",
        "market": "CN",
    },
]
```

##### ğŸ”— è·¨è¡¨è”åˆæŸ¥è¯¢ (category: `composite`)

```python
SQL_EXAMPLES_COMPOSITE = [
    {
        "question": "èµ›åŠ›æ–¯æœ€è¿‘ä¸€å‘¨çš„ä»·æ ¼å’ŒMACDæŒ‡æ ‡ä¸€èµ·çœ‹",
        "sql_query": """SELECT p.ticker, p.trade_date, p.close, p.volume,
       t.macd_diff, t.macd_dea, t.macd_hist
FROM stock_daily_price p
JOIN stock_technical_indicators t
  ON p.ticker = t.ticker AND p.trade_date = t.trade_date
WHERE p.ticker = '601127'
ORDER BY p.trade_date DESC
LIMIT 7;""",
        "description": "ä»·æ ¼ + æŠ€æœ¯æŒ‡æ ‡åŒè¡¨ JOINï¼Œå±•ç¤º ticker + trade_date è”åˆé”®",
        "category": "composite",
        "tables_involved": ["stock_daily_price", "stock_technical_indicators"],
        "difficulty": "medium",
        "market": "CN",
    },
    {
        "question": "Teslaçš„è‚¡ä»·åŠ ä¸ŠåŸºæœ¬é¢æ•°æ®",
        "sql_query": """SELECT p.ticker, p.trade_date, p.close,
       f.gross_margin, f.net_margin, f.price_to_earnings_ratio
FROM stock_daily_price p
LEFT JOIN financial_metrics f
  ON p.ticker = f.ticker
  AND f.report_period = (
    SELECT MAX(report_period) FROM financial_metrics WHERE ticker = p.ticker
  )
WHERE p.ticker = 'TSLA'
ORDER BY p.trade_date DESC
LIMIT 10;""",
        "description": "ä»·æ ¼ + è´¢åŠ¡è·¨è¡¨ JOINï¼Œå±•ç¤ºå­æŸ¥è¯¢è·å–æœ€æ–°è´¢æŠ¥æœŸ",
        "category": "composite",
        "tables_involved": ["stock_daily_price", "financial_metrics"],
        "difficulty": "hard",
        "market": "US",
    },
]
```

#### 8.3.4 LLM æ‰¹é‡æ‰©å…… â€” æ•´ä½“æµç¨‹

é™¤äº†äººå·¥ç§å­ç¤ºä¾‹ï¼Œä½¿ç”¨ LLM æŒ‰ç±»åˆ«æ‰¹é‡æ‰©å……ä»¥è¦†ç›–æ›´å¤šæŸ¥è¯¢å˜ä½“ã€‚æ•´ä½“æµç¨‹å¦‚ä¸‹ï¼š

```mermaid
flowchart TD
    subgraph SEED["Phase 1: ç§å­å‡†å¤‡"]
        S1["äººå·¥ç¼–å†™ç§å­ç¤ºä¾‹<br/>æ¯ç±» 3-5 æ¡"]
        S2["æå–æ•°æ®åº“ DDL Schema<br/>get_table_schemas()"]
        S3["åŠ è½½ MVP è‚¡ç¥¨æ± <br/>MVP_STOCK_UNIVERSE"]
    end

    subgraph EXPAND["Phase 2: LLM æ‰¹é‡æ‰©å……"]
        E1["æŒ‰ç±»åˆ«æ„é€  Prompt<br/>category-specific prompt"]
        E2["è°ƒç”¨ LLM ç”Ÿæˆ<br/>æ¯ç±» 5-10 æ¡"]
        E3["JSON è§£æ + ç»“æ„æ ¡éªŒ<br/>Pydantic éªŒè¯"]
    end

    subgraph VALIDATE["Phase 3: è´¨é‡æ ¡éªŒ"]
        V1["SQL è¯­æ³•æ£€æµ‹<br/>sqlparse / EXPLAIN"]
        V2["è¡¨å/åˆ—åæ ¡éªŒ<br/>ç™½åå•æ¯”å¯¹"]
        V3["è¯­ä¹‰å»é‡<br/>Embedding ä½™å¼¦ç›¸ä¼¼åº¦ > 0.92 â†’ å‰”é™¤"]
    end

    subgraph PERSIST["Phase 4: å‘é‡åŒ–å…¥åº“"]
        P1["question â†’ Embedding"]
        P2["UPSERT sql_examples_embeddings<br/>ä»¥ question hash ä½œå¹‚ç­‰é”®"]
    end

    SEED --> EXPAND --> VALIDATE --> PERSIST
```

#### 8.3.5 LLM æ‰©å…… Prompt è®¾è®¡

> [!IMPORTANT]
> Prompt æŒ‰ **ç±»åˆ«** åˆ†åˆ«è®¾è®¡ã€‚æ¯ä¸ªç±»åˆ«æœ‰ä¸åŒçš„ä¾§é‡ç‚¹å’Œçº¦æŸã€‚é€šç”¨éƒ¨åˆ†æŠ½ä¸º `BASE_SYSTEM_PROMPT`ï¼Œç±»åˆ«ç‰¹æœ‰æŒ‡å¯¼ä½œä¸º `CATEGORY_GUIDANCE` æ³¨å…¥ã€‚

##### é€šç”¨ System Prompt (æ‰€æœ‰ç±»åˆ«å…±äº«)

```python
BASE_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ SQL ç¤ºä¾‹ç”ŸæˆåŠ©æ‰‹ï¼Œä¸ºè‚¡ç¥¨åˆ†æ AI Agent çš„ Text-to-SQL åŠŸèƒ½ç”Ÿæˆè®­ç»ƒæ•°æ®ã€‚

## æ•°æ®åº“ Schema (PostgreSQL)

{schema}

## MVP è‚¡ç¥¨æ± 

| å¸‚åœº | ä»£ç  | åç§° |
|------|------|------|
| Aè‚¡ | 601127 | èµ›åŠ›æ–¯ |
| Aè‚¡ | 688981 | ä¸­èŠ¯å›½é™… |
| æ¸¯è‚¡ | 9988.HK | é˜¿é‡Œå·´å·´ |
| æ¸¯è‚¡ | 0700.HK | è…¾è®¯ |
| æ¸¯è‚¡ | 1024.HK | å¿«æ‰‹ |
| ç¾è‚¡ | AAPL | è‹¹æœ |
| ç¾è‚¡ | MSFT | å¾®è½¯ |
| ç¾è‚¡ | NVDA | è‹±ä¼Ÿè¾¾ |
| ç¾è‚¡ | GOOG | è°·æ­Œ |
| ç¾è‚¡ | AMZN | äºšé©¬é€Š |
| ç¾è‚¡ | META | Meta |
| ç¾è‚¡ | TSLA | ç‰¹æ–¯æ‹‰ |

## ä¸¥æ ¼çº¦æŸ

1. **question** å¿…é¡»ç”¨è‡ªç„¶è¯­è¨€ä¸­æ–‡æé—®ï¼Œæ¨¡æ‹ŸçœŸå®æ•£æˆ·æŠ•èµ„è€…çš„å£è¯­åŒ–è¡¨è¿°
2. **sql_query** å¿…é¡»æ˜¯åˆæ³•çš„ PostgreSQL SELECT è¯­å¥ï¼Œç¦æ­¢ INSERT/UPDATE/DELETE
3. **ä»…ä½¿ç”¨ä¸Šè¿° Schema ä¸­å­˜åœ¨çš„è¡¨åå’Œåˆ—å**ï¼Œä¸è¦è‡†é€ ä¸å­˜åœ¨çš„å­—æ®µ
4. **ticker å¿…é¡»æ¥è‡ªä¸Šè¿°è‚¡ç¥¨æ± **ï¼Œä¸è¦ä½¿ç”¨ä¸åœ¨åˆ—è¡¨ä¸­çš„è‚¡ç¥¨ä»£ç 
5. æ¯æ¡ç¤ºä¾‹çš„ question å¿…é¡»ä¸å·²æœ‰ç¤ºä¾‹ **è¯­ä¹‰ä¸åŒ**ï¼ˆä¸æ˜¯ç®€å•æ¢è‚¡ç¥¨åï¼‰
6. SQL ä¸­çš„æ—¥æœŸå¤„ç†ä½¿ç”¨ PostgreSQL æ ‡å‡†è¯­æ³•ï¼š`CURRENT_DATE`, `INTERVAL`, `DATE_TRUNC`
7. trade_date å­—æ®µç±»å‹ä¸º VARCHAR(10)ï¼Œæ ¼å¼ 'YYYY-MM-DD'ï¼Œæ¯”è¾ƒæ—¶æ³¨æ„ç±»å‹è½¬æ¢

## è¾“å‡ºæ ¼å¼

ä¸¥æ ¼è¾“å‡º JSON æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
```json
[
  {{
    "question": "è‡ªç„¶è¯­è¨€é—®é¢˜",
    "sql_query": "SELECT ... FROM ...",
    "description": "è¿™ä¸ªæŸ¥è¯¢åšäº†ä»€ä¹ˆã€æ•™äº† LLM ä»€ä¹ˆæŠ€å·§",
    "category": "{category}",
    "tables_involved": ["table1", "table2"],
    "difficulty": "easy|medium|hard",
    "market": "CN|HK|US|ALL"
  }}
]
```

ä¸è¦è¾“å‡º JSON ä»¥å¤–çš„ä»»ä½•å†…å®¹ã€‚
"""
```

##### åˆ†ç±»åˆ« Prompt æŒ‡å¯¼ (CATEGORY_GUIDANCE)

```python
CATEGORY_GUIDANCE = {
    "price": """## ç±»åˆ«æŒ‡å¯¼: ä»·æ ¼æŸ¥è¯¢ (price)

æ¶‰åŠè¡¨: stock_daily_price
é‡ç‚¹è¦†ç›–çš„æŸ¥è¯¢æ¨¡å¼:
- å•è‚¡è¿‘ N å¤©/å‘¨/æœˆçš„ä»·æ ¼èµ°åŠ¿
- æ¶¨è·Œå¹…æ’åº (pct_change)
- å¤šè‚¡æ¨ªå‘å¯¹æ¯” (IN å­å¥ + åˆ†ç»„)
- ä»·æ ¼åŒºé—´ç»Ÿè®¡ (MAX/MIN/AVG)
- æˆäº¤é‡æ”¾å¤§/ç¼©å° (volume å¯¹æ¯”)
- è¿ç»­æ¶¨è·Œå¤©æ•° (çª—å£å‡½æ•° LAG)
- æ¢æ‰‹ç‡å¼‚å¸¸ (turnover_rate æ’åº)

è¯·ç¡®ä¿è¦†ç›–ä»¥ä¸‹æŸ¥è¯¢æŠ€å·§å„è‡³å°‘ 1 æ¡:
- WHERE + ORDER BY + LIMIT
- GROUP BY + èšåˆå‡½æ•° (AVG, MAX, MIN, SUM)
- çª—å£å‡½æ•° (LAG, ROW_NUMBER)
- CASE WHEN æ¡ä»¶åˆ¤æ–­
""",

    "indicator": """## ç±»åˆ«æŒ‡å¯¼: æŠ€æœ¯æŒ‡æ ‡æŸ¥è¯¢ (indicator)

æ¶‰åŠè¡¨: stock_technical_indicators
é‡ç‚¹è¦†ç›–çš„æŸ¥è¯¢æ¨¡å¼:
- å•æŒ‡æ ‡æœ€æ–°å€¼æŸ¥è¯¢ (MACD, RSI, KDJ, å¸ƒæ—å¸¦, å‡çº¿)
- é‡‘å‰/æ­»å‰åˆ¤æ–­ (MACD: macd_diff ä¸ macd_dea äº¤å‰; KDJ: kdj_k ä¸ kdj_d äº¤å‰)
- è¶…ä¹°/è¶…å–åˆ¤æ–­ (RSI > 70 / RSI < 30)
- å‡çº¿å¤šå¤´/ç©ºå¤´æ’åˆ— (ma5 > ma10 > ma20 > ma30)
- å¸ƒæ—å¸¦ä½ç½®åˆ¤æ–­ (close ä¸ boll_upper/boll_lower å…³ç³»)
- å¤šæŒ‡æ ‡ç»„åˆç­›é€‰ (å¦‚ MACDé‡‘å‰ + RSIæœªè¶…ä¹°)
- æŒ‡æ ‡ä¸å‰æ—¥å¯¹æ¯” (LAG çª—å£å‡½æ•°)

æ³¨æ„: è¯¥è¡¨çš„ MACD ç›¸å…³å­—æ®µåæ˜¯ macd_diff, macd_dea, macd_hist (ä¸æ˜¯ macd, macd_signal)
""",

    "signal": """## ç±»åˆ«æŒ‡å¯¼: ç­–ç•¥ä¿¡å·æŸ¥è¯¢ (signal)

æ¶‰åŠè¡¨ (5 å¼ ç­–ç•¥ä¿¡å·è¡¨):
- stock_technical_trend_signal_indicators: è¶‹åŠ¿è·Ÿè¸ª (trend_signal, trend_strength, trend_confidence, adx, ema_8/21/55)
- stock_technical_mean_reversion_signal_indicators: å‡å€¼å›å½’ (mean_reversion_signal, z_score, price_vs_bb, rsi_14)
- stock_technical_momentum_signal_indicators: åŠ¨é‡ (momentum_signal, momentum_score, mom_1m/3m/6m, volume_momentum)
- stock_technical_volatility_signal_indicators: æ³¢åŠ¨ç‡ (volatility_signal, hist_vol_21, atr_14, vol_z_score)
- stock_technical_stat_arb_signal_indicators: ç»Ÿè®¡å¥—åˆ© (stat_arb_signal, hurst_exponent, skew_63, kurt_63)

é‡ç‚¹è¦†ç›–çš„æŸ¥è¯¢æ¨¡å¼:
- æŸè‚¡ç¥¨æŸç­–ç•¥æœ€æ–°ä¿¡å·æ˜¯ä»€ä¹ˆ
- å“ªäº›è‚¡ç¥¨å½“å‰æ˜¯ bullish ä¿¡å·
- æŸç­–ç•¥ä¿¡å·ç½®ä¿¡åº¦æ’å
- å¤šç­–ç•¥å…±æŒ¯ (å¤šè¡¨ JOIN: è¶‹åŠ¿ + åŠ¨é‡åŒæ—¶ bullish)
- ä¿¡å·å˜åŒ–æ£€æµ‹ (JOIN + LAG: ä¿¡å·ä» bearish è½¬ bullish)
""",

    "financial": """## ç±»åˆ«æŒ‡å¯¼: è´¢åŠ¡æ•°æ®æŸ¥è¯¢ (financial)

æ¶‰åŠè¡¨: financial_metrics
é‡ç‚¹è¦†ç›–çš„æŸ¥è¯¢æ¨¡å¼:
- æœ€æ–°ä¸€æœŸè´¢åŠ¡æŒ‡æ ‡ (æŒ‰ report_period DESC)
- ç›ˆåˆ©èƒ½åŠ›å¯¹æ¯” (gross_margin, operating_margin, net_margin)
- ä¼°å€¼æŒ‡æ ‡ (price_to_earnings_ratio / PE, price_to_book_ratio / PB, price_to_sales_ratio / PS)
- ROE/ROA/ROIC å›æŠ¥ç‡æ¯”è¾ƒ
- è´Ÿå€ºé£é™© (debt_to_equity, current_ratio, interest_coverage)
- æˆé•¿æ€§åˆ†æ (revenue_growth, earnings_growth å¤šæœŸè¶‹åŠ¿)
- å¤šè‚¡è´¢åŠ¡æ¨ªå‘å¯¹æ¯” (IN å­å¥ + æ’åº)
- åŒæ¯”/ç¯æ¯”å˜åŒ– (LAG çª—å£å‡½æ•° + report_period æ’åº)

æ³¨æ„:
- report_period æ˜¯ VARCHAR(20)ï¼Œæ ¼å¼å¦‚ '2024-Q3', '2024-FY'
- period å­—æ®µæ ‡è¯†ç±»å‹: 'Q1','Q2','Q3','Q4','H1','H2','FY'
- PE å­—æ®µåæ˜¯ price_to_earnings_ratio (ä¸æ˜¯ pe_ratio)
- ROE å­—æ®µåæ˜¯ return_on_equity (ä¸æ˜¯ roe)
""",

    "meta": """## ç±»åˆ«æŒ‡å¯¼: å…ƒæ•°æ®/åŸºæœ¬ä¿¡æ¯æŸ¥è¯¢ (meta)

æ¶‰åŠè¡¨: stock_basic_info, stock_company_info, stock_basic_info_a
é‡ç‚¹è¦†ç›–çš„æŸ¥è¯¢æ¨¡å¼:
- æŸ¥æŸè‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ (åç§°ã€è¡Œä¸šã€ä¸Šå¸‚æ—¶é—´)
- æŒ‰è¡Œä¸šç­›é€‰ (industry ILIKE '%å…³é”®è¯%')
- æŒ‰å¸‚å€¼æ’åº (total_market_value)
- å…¬å¸è¯¦æƒ… (æ³¨å†Œèµ„é‡‘ã€æ³•äººä»£è¡¨ã€å®˜ç½‘ â€” stock_company_info)
- æ²ªæ·±æ¸¯é€šæ ‡çš„ç­›é€‰ (stock_basic_info_a.is_hs)
- ä¸¤å¼ ä¿¡æ¯è¡¨ JOIN (stock_basic_info + stock_company_info)
""",

    "composite": """## ç±»åˆ«æŒ‡å¯¼: è·¨è¡¨è”åˆæŸ¥è¯¢ (composite)

æ¶‰åŠå¤šå¼ è¡¨çš„ JOIN æŸ¥è¯¢,è¿™æ˜¯æœ€é‡è¦çš„ç±»åˆ«:
é‡ç‚¹è¦†ç›–çš„æŸ¥è¯¢æ¨¡å¼:
- ä»·æ ¼ + æŠ€æœ¯æŒ‡æ ‡ (stock_daily_price JOIN stock_technical_indicators)
- ä»·æ ¼ + ç­–ç•¥ä¿¡å· (stock_daily_price JOIN stock_technical_*_signal_indicators)
- ä»·æ ¼ + è´¢åŠ¡ (stock_daily_price JOIN financial_metrics)
- åŸºæœ¬ä¿¡æ¯ + ä»·æ ¼ (stock_basic_info JOIN stock_daily_price)
- ä¸‰è¡¨è”åˆ (åŸºæœ¬ä¿¡æ¯ + ä»·æ ¼ + æŒ‡æ ‡)
- å¤šç­–ç•¥å…±æŒ¯ (è¶‹åŠ¿ JOIN åŠ¨é‡ JOIN å‡å€¼å›å½’)
- å­æŸ¥è¯¢/CTE æ¨¡å¼ (WITH ... AS ...)

JOIN æ—¶æ³¨æ„:
- è”åˆé”®é€šå¸¸æ˜¯ ticker + trade_date
- financial_metrics ç”¨ report_period ä¸æ˜¯ trade_date
- ä½¿ç”¨ LEFT JOIN åº”å¯¹ç¼ºå¤±æ•°æ®
- é€‚å½“ä½¿ç”¨å­æŸ¥è¯¢è·å–"æœ€æ–°ä¸€æ¡"è®°å½•
"""
}
```

##### User Prompt (è§¦å‘ç”Ÿæˆ)

```python
USER_PROMPT_TEMPLATE = """è¯·ç”Ÿæˆ {count} æ¡ **{category}** ç±»åˆ«çš„ SQL æŸ¥è¯¢ç¤ºä¾‹ã€‚

## å·²æœ‰ç¤ºä¾‹ (å‚è€ƒé£æ ¼ï¼Œä¸è¦é‡å¤)

{existing_examples}

## è¦æ±‚
- æ¯æ¡ç¤ºä¾‹çš„ question å¿…é¡»åœ¨è¯­ä¹‰ä¸Šä¸å·²æœ‰ç¤ºä¾‹ä¸åŒ
- å¤šæ ·åŒ–é—®æ³•: åŒ…å«é™ˆè¿°å¥("æˆ‘æƒ³çœ‹...")ã€ç–‘é—®å¥("...æ˜¯å¤šå°‘?")ã€å£è¯­("...å’‹æ ·?")
- å¤šæ ·åŒ–è‚¡ç¥¨: å‡åŒ€åˆ†å¸ƒåˆ°ä¸åŒå¸‚åœºçš„è‚¡ç¥¨
- å¤šæ ·åŒ–éš¾åº¦: è‡³å°‘åŒ…å« 1 æ¡ hard éš¾åº¦ (æ¶‰åŠçª—å£å‡½æ•°/å­æŸ¥è¯¢/CASE WHEN)
- description å­—æ®µè¦è¯´æ˜è¿™ä¸ªç¤ºä¾‹ **æ•™äº† LLM ä»€ä¹ˆæŸ¥è¯¢æŠ€å·§**

è¯·ç›´æ¥è¾“å‡º JSON æ•°ç»„ï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚"""
```

##### å®Œæ•´è°ƒç”¨ç¤ºä¾‹

```python
async def generate_examples_with_llm(
    category: str,
    count: int = 5,
    llm_client = None,
) -> list[dict]:
    """æŒ‰ç±»åˆ«è°ƒç”¨ LLM ç”Ÿæˆ SQL ç¤ºä¾‹"""

    # 1) ç»„è£… System Prompt = é€šç”¨éƒ¨åˆ† + ç±»åˆ«æŒ‡å¯¼
    schema_ddl = get_table_schemas()   # è¿”å›æ‰€æœ‰è¡¨çš„ CREATE TABLE DDL (å«æ³¨é‡Š)
    system_prompt = BASE_SYSTEM_PROMPT.format(
        schema=schema_ddl,
        category=category,
    ) + "\n\n" + CATEGORY_GUIDANCE.get(category, "")

    # 2) ç»„è£… User Prompt = å·²æœ‰ç¤ºä¾‹ + ç”Ÿæˆè¦æ±‚
    existing = [e for e in SEED_EXAMPLES if e["category"] == category]
    user_prompt = USER_PROMPT_TEMPLATE.format(
        count=count,
        category=category,
        existing_examples=json.dumps(existing[:3], ensure_ascii=False, indent=2),
    )

    # 3) è°ƒç”¨ LLM
    response = await llm_client.chat([
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_prompt),
    ])

    # 4) è§£æ JSON + Pydantic æ ¡éªŒ
    raw = extract_json_from_response(response.content)
    validated = [SQLExample(**item).model_dump() for item in raw]

    return validated
```

#### 8.3.6 è´¨é‡æ ¡éªŒä¸å»é‡

LLM ç”Ÿæˆçš„ç¤ºä¾‹éœ€è¦ç»è¿‡ä¸‰é“æ ¡éªŒï¼š

```python
# ---- æ ¡éªŒ 1: SQL è¯­æ³• (sqlparse) ----
import sqlparse

def validate_sql_syntax(sql: str) -> bool:
    """åŸºç¡€ SQL è¯­æ³•æ£€æŸ¥"""
    parsed = sqlparse.parse(sql)
    if not parsed:
        return False
    stmt = parsed[0]
    # å¿…é¡»æ˜¯ SELECT è¯­å¥
    if stmt.get_type() != "SELECT":
        return False
    return True


# ---- æ ¡éªŒ 2: è¡¨å/åˆ—åç™½åå• ----
VALID_TABLES = {
    "stock_daily_price", "stock_technical_indicators",
    "stock_technical_trend_signal_indicators",
    "stock_technical_mean_reversion_signal_indicators",
    "stock_technical_momentum_signal_indicators",
    "stock_technical_volatility_signal_indicators",
    "stock_technical_stat_arb_signal_indicators",
    "financial_metrics", "stock_basic_info",
    "stock_basic_info_a", "stock_company_info",
}

def validate_tables(tables_involved: list[str]) -> bool:
    """æ£€æŸ¥æ¶‰åŠçš„è¡¨åæ˜¯å¦åœ¨å·²çŸ¥ Schema ä¸­"""
    return all(t in VALID_TABLES for t in tables_involved)


# ---- æ ¡éªŒ 3: è¯­ä¹‰å»é‡ (Embedding ä½™å¼¦ç›¸ä¼¼åº¦) ----
import numpy as np

async def deduplicate_examples(
    new_examples: list[dict],
    existing_embeddings: list[np.ndarray],
    existing_questions: list[str],
    embedding_provider,
    threshold: float = 0.92,
) -> list[dict]:
    """
    å¯¹æ–°ç”Ÿæˆçš„ç¤ºä¾‹é€æ¡ä¸å·²æœ‰ç¤ºä¾‹åš Embedding ä½™å¼¦ç›¸ä¼¼åº¦æ¯”å¯¹ã€‚
    ç›¸ä¼¼åº¦ > threshold çš„è§†ä¸ºé‡å¤ï¼Œå‰”é™¤ã€‚
    """
    kept = []
    for example in new_examples:
        vec = await embedding_provider.embed_query(example["question"])
        is_dup = False
        for i, existing_vec in enumerate(existing_embeddings):
            similarity = np.dot(vec, existing_vec) / (
                np.linalg.norm(vec) * np.linalg.norm(existing_vec)
            )
            if similarity > threshold:
                print(f"  âš ï¸ é‡å¤å‰”é™¤: '{example['question']}' "
                      f"â‰ˆ '{existing_questions[i]}' (sim={similarity:.3f})")
                is_dup = True
                break
        if not is_dup:
            example["_embedding"] = vec  # ç¼“å­˜ embeddingï¼Œåç»­å…¥åº“å¤ç”¨
            kept.append(example)
            # å°†æ–°ä¾‹åŠ å…¥å·²æœ‰é›†åˆï¼Œæ”¯æŒå†…éƒ¨å»é‡
            existing_embeddings.append(vec)
            existing_questions.append(example["question"])
    return kept
```

#### 8.3.7 å®Œæ•´å…¥åº“è„šæœ¬ (`data_pipeline/sql_examples_seeder.py`)

```python
#!/usr/bin/env python3
"""
SQL ç¤ºä¾‹é¢„ç”Ÿæˆ & å…¥åº“è„šæœ¬

ç”¨æ³•:
  # ä»…å†™å…¥äººå·¥ç§å­ (å®‰å…¨ã€æ—  LLM ä¾èµ–)
  python -m data_pipeline.sql_examples_seeder --seed-only

  # ç§å­ + LLM æ‰©å…… (éœ€è¦ LLM API)
  python -m data_pipeline.sql_examples_seeder --expand --count 8

  # å¹²è·‘ (åªæ‰“å°ä¸å…¥åº“ï¼Œç”¨äºå®¡æ ¸)
  python -m data_pipeline.sql_examples_seeder --expand --dry-run
"""

import argparse
import asyncio
import hashlib
import json
from typing import Optional

# ---- äººå·¥ç§å­ç¤ºä¾‹ ----
SEED_EXAMPLES = (
    SQL_EXAMPLES_PRICE
    + SQL_EXAMPLES_INDICATOR
    + SQL_EXAMPLES_SIGNAL
    + SQL_EXAMPLES_FINANCIAL
    + SQL_EXAMPLES_META
    + SQL_EXAMPLES_COMPOSITE
)

CATEGORIES = ["price", "indicator", "signal", "financial", "meta", "composite"]


def question_hash(question: str) -> str:
    """question æ–‡æœ¬ â†’ MD5 hash (ç”¨äºå¹‚ç­‰ UPSERT)"""
    return hashlib.md5(question.strip().encode()).hexdigest()


async def seed_sql_examples(
    expand: bool = False,
    count_per_category: int = 5,
    dry_run: bool = False,
):
    """
    ä¸»å…¥å£: åˆå§‹åŒ– SQL ç¤ºä¾‹å‘é‡åº“
    
    Args:
        expand: æ˜¯å¦å¯ç”¨ LLM æ‰©å……
        count_per_category: LLM æ¯ç±»åˆ«ç”Ÿæˆæ¡æ•°
        dry_run: ä»…æ‰“å°ä¸å…¥åº“
    """
    settings = get_settings()
    embedding_provider = create_embedding_provider(settings)
    
    all_examples: list[dict] = list(SEED_EXAMPLES)
    print(f"ğŸ“ äººå·¥ç§å­ç¤ºä¾‹: {len(all_examples)} æ¡")

    # ---- Phase 2: LLM æ‰©å…… (å¯é€‰) ----
    if expand:
        llm_client = create_llm_client(settings)
        for category in CATEGORIES:
            print(f"\nğŸ¤– LLM æ‰©å……ç±»åˆ«: {category} (ç›®æ ‡ {count_per_category} æ¡)")
            try:
                generated = await generate_examples_with_llm(
                    category=category,
                    count=count_per_category,
                    llm_client=llm_client,
                )
                # è´¨é‡æ ¡éªŒ â€” è¯­æ³• + è¡¨å
                valid = []
                for ex in generated:
                    if not validate_sql_syntax(ex["sql_query"]):
                        print(f"  âŒ SQL è¯­æ³•æ— æ•ˆ: {ex['question'][:30]}...")
                        continue
                    if not validate_tables(ex["tables_involved"]):
                        print(f"  âŒ è¡¨åæ— æ•ˆ: {ex['tables_involved']}")
                        continue
                    valid.append(ex)
                print(f"  âœ… è¯­æ³•æ ¡éªŒé€šè¿‡: {len(valid)}/{len(generated)} æ¡")
                all_examples.extend(valid)
            except Exception as e:
                print(f"  âš ï¸ LLM æ‰©å…… {category} å¤±è´¥: {e}, è·³è¿‡")

    # ---- Phase 3: è¯­ä¹‰å»é‡ ----
    print(f"\nğŸ” å»é‡å‰: {len(all_examples)} æ¡")
    existing_embeddings = []
    existing_questions = []
    deduplicated = await deduplicate_examples(
        all_examples, existing_embeddings, existing_questions,
        embedding_provider, threshold=0.92,
    )
    print(f"ğŸ” å»é‡å: {len(deduplicated)} æ¡ (å‰”é™¤ {len(all_examples) - len(deduplicated)} æ¡)")

    # ---- Phase 4: å‘é‡åŒ– + å…¥åº“ ----
    if dry_run:
        print(f"\nğŸƒ Dry-run æ¨¡å¼ï¼Œæ‰“å°ç»“æœ:")
        for ex in deduplicated:
            print(f"  [{ex['category']}][{ex['difficulty']}] {ex['question']}")
        return

    success_count = 0
    for ex in deduplicated:
        vector = ex.pop("_embedding", None)
        if vector is None:
            vector = await embedding_provider.embed_query(ex["question"])
        
        await upsert_sql_example(
            question_hash=question_hash(ex["question"]),
            question=ex["question"],
            sql_query=ex["sql_query"],
            description=ex.get("description", ""),
            category=ex["category"],
            tables_involved=ex["tables_involved"],
            difficulty=ex["difficulty"],
            market=ex.get("market", "ALL"),
            embedding=vector,
        )
        success_count += 1

    print(f"\nâœ… å…±å…¥åº“ {success_count} æ¡ SQL ç¤ºä¾‹")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="SQL ç¤ºä¾‹é¢„ç”Ÿæˆ & å…¥åº“")
    parser.add_argument("--seed-only", action="store_true", help="ä»…å†™å…¥äººå·¥ç§å­")
    parser.add_argument("--expand", action="store_true", help="å¯ç”¨ LLM æ‰¹é‡æ‰©å……")
    parser.add_argument("--count", type=int, default=5, help="LLM æ¯ç±»åˆ«ç”Ÿæˆæ¡æ•°")
    parser.add_argument("--dry-run", action="store_true", help="ä»…æ‰“å°ä¸å…¥åº“")
    args = parser.parse_args()

    asyncio.run(seed_sql_examples(
        expand=args.expand and not args.seed_only,
        count_per_category=args.count,
        dry_run=args.dry_run,
    ))
```

#### 8.3.8 è¿è¡Œæ—¶ Text-to-SQL Prompt æ¨¡æ¿

`text_to_sql_tool` åœ¨è¿è¡Œæ—¶æ£€ç´¢ Few-shot ç¤ºä¾‹å¹¶æ³¨å…¥ LLM Promptã€‚ä»¥ä¸‹æ˜¯å®Œæ•´çš„ Prompt æ¨¡æ¿ï¼š

```
ç”¨æˆ·: "ä¸­èŠ¯å›½é™…æœ€è¿‘çš„MACDé‡‘å‰äº†å—"
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Embedding("ä¸­èŠ¯å›½é™…MACDé‡‘å‰")  â”‚
â”‚    â†’ query_vector               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. pgvector æ£€ç´¢ Top-3 ç›¸ä¼¼ç¤ºä¾‹   â”‚
â”‚    cosine similarity æ’åº        â”‚
â”‚    â†’ æœ€ç›¸ä¼¼: "ä¸­èŠ¯å›½é™…æœ€è¿‘çš„MACD"  â”‚
â”‚    â†’ æ¬¡ç›¸ä¼¼: "å¿«æ‰‹RSIæ˜¯å¦è¶…ä¹°"     â”‚
â”‚    â†’ ç¬¬ä¸‰: "Teslaå¸ƒæ—å¸¦æ”¶çª„äº†å—"   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. æ„å»º LLM Prompt               â”‚
â”‚    System: schema + examples     â”‚
â”‚    User: åŸå§‹é—®é¢˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. LLM ç”Ÿæˆ SQL + æ‰§è¡Œ + è¿”å›ç»“æœ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

##### Text-to-SQL System Prompt

```python
TEXT_TO_SQL_PROMPT = """ä½ æ˜¯ä¸€ä¸ª PostgreSQL æŸ¥è¯¢ç”Ÿæˆä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€é—®é¢˜ï¼Œç”Ÿæˆå‡†ç¡®çš„ SQL æŸ¥è¯¢ã€‚

## æ•°æ®åº“ Schema

{schema}

## å‚è€ƒç¤ºä¾‹ (Few-shot)

ä»¥ä¸‹æ˜¯ä¸ç”¨æˆ·é—®é¢˜æœ€ç›¸ä¼¼çš„æŸ¥è¯¢ç¤ºä¾‹ï¼Œè¯·å‚è€ƒå®ƒä»¬çš„é£æ ¼å’Œæ¨¡å¼ï¼š

{few_shot_examples}

## è§„åˆ™

1. åªç”Ÿæˆ SELECT æŸ¥è¯¢ï¼Œç¦æ­¢ä»»ä½•ä¿®æ”¹æ•°æ®çš„è¯­å¥
2. ä¸¥æ ¼ä½¿ç”¨ä¸Šè¿° Schema ä¸­å­˜åœ¨çš„è¡¨åå’Œåˆ—å
3. trade_date æ˜¯ VARCHAR(10) æ ¼å¼ 'YYYY-MM-DD'ï¼Œæ—¥æœŸæ¯”è¾ƒæ—¶æ³¨æ„ï¼š
   - æ­£ç¡®: WHERE trade_date >= '2024-01-01'
   - æ­£ç¡®: WHERE trade_date >= TO_CHAR(CURRENT_DATE - INTERVAL '30 days', 'YYYY-MM-DD')
4. é»˜è®¤è¿”å›æœ€è¿‘çš„æ•°æ® (ORDER BY trade_date DESC)
5. æœ‰æ˜ç¡®æ•°é‡é™åˆ¶æ—¶ç”¨ LIMITï¼Œå¦åˆ™é»˜è®¤ LIMIT 30 é˜²æ­¢è¿”å›è¿‡å¤š
6. å¤šè¡¨ JOIN æ—¶ä½¿ç”¨ ticker + trade_date ä½œä¸ºè”åˆé”®
7. å¦‚æœé—®é¢˜æ¶‰åŠ"é‡‘å‰"/"æ­»å‰"ï¼Œéœ€è¦ç”¨ LAG çª—å£å‡½æ•°å¯¹æ¯”å‰ä¸€æ—¥

## è¾“å‡ºæ ¼å¼

åªè¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡:
```json
{{
  "sql": "SELECT ...",
  "explanation": "ç®€è¦è§£é‡ŠæŸ¥è¯¢é€»è¾‘"
}}
```
"""


def build_few_shot_section(examples: list[dict]) -> str:
    """å°†æ£€ç´¢åˆ°çš„ Top-K ç¤ºä¾‹æ ¼å¼åŒ–ä¸º Prompt ç‰‡æ®µ"""
    parts = []
    for i, ex in enumerate(examples, 1):
        parts.append(f"""### ç¤ºä¾‹ {i}
**é—®é¢˜**: {ex['question']}
**SQL**:
```sql
{ex['sql_query']}
```
**è¯´æ˜**: {ex.get('description', '')}
""")
    return "\n".join(parts)
```

### 8.4 è°ƒåº¦é¢‘ç‡

> [!NOTE]
> MVP é˜¶æ®µå…¨éƒ¨æ‰‹åŠ¨æ‰§è¡Œï¼Œä»¥ä¸‹é¢‘ç‡ä»…ä½œåæœŸè‡ªåŠ¨åŒ–å‚è€ƒã€‚

| ä»»åŠ¡ | é¢‘ç‡ | è§¦å‘æ—¶é—´ | æ‰§è¡Œæ–¹å¼ |
|------|------|----------|----------|
| Aè‚¡æ—¥K | æ¯æ—¥ | 15:30 CST | `python -m data_pipeline.akshare_fetcher` |
| æ¸¯è‚¡æ—¥K | æ¯æ—¥ | 16:15 HKT | `python -m data_pipeline.yfinance_fetcher` |
| ç¾è‚¡æ—¥K | æ¯æ—¥ | 06:00 CST (æ¬¡æ—¥) | `python -m data_pipeline.yfinance_fetcher` |
| æŠ€æœ¯æŒ‡æ ‡ | æ¯æ—¥ | Kçº¿å…¥åº“å | `python -m data_pipeline.indicator_calculator` |
| æ–°é—» | æ¯æ—¥ 1-2 æ¬¡ | æŒ‰éœ€ | `python -m data_pipeline.news_fetcher` |
| æ–°é—»å‘é‡åŒ– | æ–°é—»å…¥åº“å | æŒ‰éœ€ | `python -m data_pipeline.embedding_pipeline` |
| SQL ç¤ºä¾‹ | ä¸€æ¬¡æ€§ | åˆå§‹åŒ–æ—¶ | `python -m data_pipeline.sql_examples_seeder` |
| è´¢åŠ¡æ•°æ® | æ¯å­£ | è´¢æŠ¥å‘å¸ƒå | æ‰‹åŠ¨ |

---

## 9. Prompt å·¥ç¨‹ (`agent/prompts/`)

### 9.1 æ„å›¾åˆ†ç±» Prompt ç»“æ„

```python
INTENT_PROMPT = """ä½ æ˜¯ä¸€ä¸ªè‚¡ç¥¨åˆ†æ Agent çš„æ„å›¾åˆ†ç±»æ¨¡å—ã€‚

## ä»»åŠ¡
åˆ†æç”¨æˆ·çš„é—®é¢˜ï¼Œè¾“å‡ºç»“æ„åŒ–çš„æ„å›¾åˆ†ç±»ç»“æœã€‚

## 6 å¤§æ„å›¾ç±»åˆ«
1. simple_query: ç®€å•äº‹å®æŸ¥è¯¢ (ä»·æ ¼ã€åŸºæœ¬ä¿¡æ¯)
2. technical_analysis: æŠ€æœ¯åˆ†æ (Kçº¿ã€æŒ‡æ ‡ã€ç­–ç•¥ä¿¡å·)
3. financial_analysis: åŸºæœ¬é¢/è´¢åŠ¡åˆ†æ (PEã€ROEã€è¥æ”¶)
4. news_sentiment: æ–°é—»èˆ†æƒ…åˆ†æ
5. composite: ç»¼åˆåˆ†æ (å¤šç»´åº¦äº¤å‰)
6. comparison: å¯¹æ¯”åˆ†æ (å¤šåªè‚¡ç¥¨)

## åˆ¤æ–­ requires_decomposition
- æ¶‰åŠå¤šä¸ªå·¥å…· â†’ True
- åŒ…å« "ç»“åˆ"/"ç»¼åˆ"/"åˆ†æ" ç­‰è¯ â†’ True
- ç®€å•æŸ¥è¯¢å•ä¸€æ•°æ® â†’ False

## è¾“å‡ºæ ¼å¼
ä¸¥æ ¼æŒ‰ IntentClassification schema è¾“å‡º JSONã€‚
"""
```

### 9.2 ç»¼åˆåˆ†æ Prompt ç»“æ„

```python
SYNTHESIS_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‚¡ç¥¨åˆ†æå¸ˆã€‚

## ä»»åŠ¡
åŸºäºä»¥ä¸‹å¤šç»´åº¦æ•°æ®ï¼Œå¯¹ç”¨æˆ·çš„é—®é¢˜è¿›è¡Œç»¼åˆåˆ†æã€‚

## æä¾›çš„æ•°æ®
{tool_results}

## è¾“å‡ºè¦æ±‚
1. **æ ¸å¿ƒç»“è®º**: 1-2 å¥æ€»ç»“
2. **è¯¦ç»†åˆ†æ**: åˆ†ç»´åº¦å±•å¼€ (ä»·æ ¼èµ°åŠ¿/æŠ€æœ¯é¢/åŸºæœ¬é¢/æ–°é—»é¢)
3. **é£é™©æç¤º**: å®¢è§‚åˆ—å‡ºæ½œåœ¨é£é™©
4. **æ•°æ®æ¥æº**: æ ‡æ³¨å¼•ç”¨çš„æ•°æ®æ¥æº [1] [2] ...

## é‡è¦å£°æ˜
ä½ çš„åˆ†æä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚
"""
```

---

## 10. é”™è¯¯å¤„ç†ä¸é‡è¯•

### 10.1 é‡è¯•ç­–ç•¥

```python
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from openai import RateLimitError, APITimeoutError


@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=10),
    retry=retry_if_exception_type((RateLimitError, APITimeoutError)),
)
async def llm_call_with_retry(messages, **kwargs):
    """å¸¦é‡è¯•çš„ LLM è°ƒç”¨"""
    return await llm_provider.chat(messages, **kwargs)
```

### 10.2 å·¥å…·çº§å®¹é”™

```python
async def safe_tool_execute(tool_fn, state, **kwargs):
    """å·¥å…·æ‰§è¡Œå®¹é”™åŒ…è£…"""
    try:
        result = await asyncio.wait_for(
            tool_fn(state, **kwargs),
            timeout=get_settings().TOOL_TIMEOUT_SECONDS,
        )
        return {"success": True, "data": result}
    except asyncio.TimeoutError:
        return {"success": False, "error": "Tool execution timeout"}
    except Exception as e:
        logger.error(f"Tool {tool_fn.__name__} failed: {e}")
        return {"success": False, "error": str(e)}
```

### 10.3 å…¨å±€å¼‚å¸¸å±‚çº§

```
APIError (è¿”å›ç»™å‰ç«¯)
â”œâ”€â”€ AgentExecutionError    # Agent æ•´ä½“æ‰§è¡Œå¤±è´¥
â”œâ”€â”€ ToolExecutionError     # å•ä¸ªå·¥å…·æ‰§è¡Œå¤±è´¥ (ä¸ä¸€å®šä¸­æ–­æ•´ä½“)
â”œâ”€â”€ LLMProviderError       # LLM API å¼‚å¸¸
â”œâ”€â”€ DatabaseError          # æ•°æ®åº“è¿æ¥/æŸ¥è¯¢å¼‚å¸¸
â””â”€â”€ ValidationError        # å‚æ•°æ ¡éªŒå¤±è´¥
```

---

## 11. ä¾èµ–æ¸…å• (`pyproject.toml`)

```toml
[project]
name = "stock-ai-agent"
version = "0.1.0"
requires-python = ">=3.12"

dependencies = [
    # ---- Web Framework ----
    "fastapi>=0.115",
    "uvicorn[standard]>=0.34",
    
    # ---- LLM & Agent ----
    "langgraph>=0.2",
    "langchain-core>=0.3",
    "pydantic-ai>=0.0.14",
    "openai>=1.50",
    "google-generativeai>=0.8",
    "zhipuai>=2.1",
    
    # ---- Database ----
    "sqlalchemy[asyncio]>=2.0",
    "asyncpg>=0.30",
    "pgvector>=0.3",
    "supabase>=2.0",
    
    # ---- Data Fetching ----
    "akshare>=1.14",
    "yfinance>=0.2.40",
    
    # ---- Computation ----
    "pandas>=2.2",
    "numpy>=1.26",
    "ta>=0.11",
    
    # ---- Utilities ----
    "pydantic>=2.9",
    "pydantic-settings>=2.5",
    "tenacity>=9.0",
    "httpx>=0.27",
    
    # ---- Frontend (Phase 1) ----
    "streamlit>=1.39",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.3",
    "pytest-asyncio>=0.24",
    "ruff>=0.7",
]
```

---

> **å…³è”æ–‡æ¡£**:
> - [PRD äº§å“éœ€æ±‚æ–‡æ¡£](./PRD_stock_ai_agent.md) â€” äº§å“å®šä¹‰ä¸éœ€æ±‚
> - [ç³»ç»Ÿæ¶æ„æ–‡æ¡£](./architecture.md) â€” é«˜å±‚æ¶æ„ä¸å†³ç­–
